data.shape (35088, 69, 4)
pred_METR-LA_GraphWaveNet_2112251644 training started Sat Dec 25 16:44:41 2021
TRAIN XS.shape YS,shape (28056, 4, 69, 12) (28056, 3, 69, 1)
Model Training Started ... Sat Dec 25 16:44:41 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          160
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-5                  [-1, 32, 69, 12]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-7                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─linear: 3-10                 [-1, 32, 69, 10]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-11                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-12                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-13                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-14                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-15                 [-1, 32, 69, 9]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-20                 [-1, 32, 69, 7]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-21                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-25                 [-1, 32, 69, 6]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-28                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-30                 [-1, 32, 69, 4]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 3]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-40                 [-1, 32, 69, 1]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 275,875
Trainable params: 275,875
Non-trainable params: 0
Total mult-adds (M): 71.81
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 11.00
Params size (MB): 1.05
Estimated Total Size (MB): 12.07
==========================================================================================
XS_torch.shape:   torch.Size([28056, 4, 69, 12])
YS_torch.shape:   torch.Size([28056, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 18  seconds  train loss: 0.2539783997817886 validation loss: 0.301074589721355
epoch 1 time used: 18  seconds  train loss: 0.21374269444467367 validation loss: 0.2887534195111625
epoch 2 time used: 17  seconds  train loss: 0.20430343373811746 validation loss: 0.2968766556732465
epoch 3 time used: 18  seconds  train loss: 0.198502409421862 validation loss: 0.2958872200486189
epoch 4 time used: 18  seconds  train loss: 0.1934829588853986 validation loss: 0.2834831810775971
epoch 5 time used: 18  seconds  train loss: 0.19059128552897409 validation loss: 0.2804767602626027
epoch 6 time used: 18  seconds  train loss: 0.18795313799792557 validation loss: 0.28436676385839815
epoch 7 time used: 18  seconds  train loss: 0.18597339597674484 validation loss: 0.2764594441793364
epoch 8 time used: 18  seconds  train loss: 0.18432614206600065 validation loss: 0.2765710777644252
epoch 9 time used: 18  seconds  train loss: 0.18252928814502825 validation loss: 0.27602958210112194
epoch 10 time used: 18  seconds  train loss: 0.18189654679175837 validation loss: 0.27562586965301217
epoch 11 time used: 19  seconds  train loss: 0.1810139767642594 validation loss: 0.27294572490146096
epoch 12 time used: 19  seconds  train loss: 0.1796532714585189 validation loss: 0.28307426496724103
epoch 13 time used: 18  seconds  train loss: 0.1785375450359274 validation loss: 0.27098471283198833
epoch 14 time used: 18  seconds  train loss: 0.1779204657773019 validation loss: 0.2726177812251468
epoch 15 time used: 18  seconds  train loss: 0.17730395248601127 validation loss: 0.2738736706783468
epoch 16 time used: 17  seconds  train loss: 0.17632071823191267 validation loss: 0.27025811810557376
epoch 17 time used: 18  seconds  train loss: 0.17611206952030098 validation loss: 0.2729278603764657
epoch 18 time used: 17  seconds  train loss: 0.1753468179883401 validation loss: 0.270426984701124
epoch 19 time used: 17  seconds  train loss: 0.174890974216575 validation loss: 0.2741054062544875
epoch 20 time used: 17  seconds  train loss: 0.17424616172452667 validation loss: 0.2728534459829806
epoch 21 time used: 17  seconds  train loss: 0.1737437758890207 validation loss: 0.27310886515964633
epoch 22 time used: 16  seconds  train loss: 0.1736479823092996 validation loss: 0.2696492744284136
epoch 23 time used: 16  seconds  train loss: 0.17281929203325622 validation loss: 0.27203006094461296
epoch 24 time used: 17  seconds  train loss: 0.17262799194742498 validation loss: 0.2706485425589735
epoch 25 time used: 16  seconds  train loss: 0.17230693221789056 validation loss: 0.274166322549864
epoch 26 time used: 16  seconds  train loss: 0.1719349363423534 validation loss: 0.2699102322141567
epoch 27 time used: 16  seconds  train loss: 0.17146181711825612 validation loss: 0.2695991597455691
epoch 28 time used: 17  seconds  train loss: 0.17118869367221343 validation loss: 0.267488486863012
epoch 29 time used: 16  seconds  train loss: 0.17061214296134253 validation loss: 0.26939280997799236
epoch 30 time used: 17  seconds  train loss: 0.17021965069184988 validation loss: 0.27326196286798643
epoch 31 time used: 16  seconds  train loss: 0.16969514444462513 validation loss: 0.2711794907240437
epoch 32 time used: 16  seconds  train loss: 0.16970359238326765 validation loss: 0.2717537361951101
epoch 33 time used: 17  seconds  train loss: 0.16946492475889632 validation loss: 0.2708174789652105
epoch 34 time used: 16  seconds  train loss: 0.16900833983934407 validation loss: 0.2729493625693624
epoch 35 time used: 16  seconds  train loss: 0.16850561471880174 validation loss: 0.2719406796157751
epoch 36 time used: 17  seconds  train loss: 0.16822387839734004 validation loss: 0.27325700079405585
epoch 37 time used: 16  seconds  train loss: 0.1680580175272816 validation loss: 0.27186422979250435
Early stopping at epoch: 38
YS.shape, YS_pred.shape before, (28056, 3, 69, 1) (28056, 3, 69, 1)
YS.shape, YS_pred.shape after, (28056, 3, 69) (28056, 3, 69)
YS_pred.shape before (28056, 3, 69)
YS_pred.shape after (28056, 3, 69)
YS.shape, YS_pred.shape, (28056, 3, 69) (28056, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 1.6516784677e-01, 0.1651678468
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 331.5909039318, 18.2096376661, 8.7285933799, 39.5831835505
Model Training Ended ... Sat Dec 25 16:56:21 2021
pred_METR-LA_GraphWaveNet_2112251644 testing started Sat Dec 25 16:56:21 2021
TEST XS.shape, YS.shape (7016, 4, 69, 12) (7016, 3, 69, 1)
Model Testing Started ... Sat Dec 25 16:56:21 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (7016, 3, 69, 1) (7016, 3, 69, 1)
YS.shape, YS_pred.shape after, (7016, 3, 69) (7016, 3, 69)
YS.shape, YS_pred.shape, (7016, 3, 69) (7016, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 3.1593490403e-01, 0.3159349040
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 563.9711136005, 23.7480759979, 11.9564507296, 47.6215618769
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 452.1495429764, 21.2638082896, 10.7276022884, 43.3052503572
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 551.3233843136, 23.4802764957, 11.8980413111, 46.9375704755
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 688.4431424241, 26.2382000607, 13.2437386323, 52.6219742492
Model Testing Ended ... Sat Dec 25 16:56:24 2021
