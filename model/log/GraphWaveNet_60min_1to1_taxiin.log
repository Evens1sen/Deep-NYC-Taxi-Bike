data.shape (17544, 69)
pred_METR-LA_GraphWaveNet_2112261652 training started Sun Dec 26 16:52:46 2021
TRAIN XS.shape YS,shape (14021, 1, 69, 12) (14021, 3, 69, 1)
Model Training Started ... Sun Dec 26 16:52:46 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-5                  [-1, 32, 69, 12]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-7                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─linear: 3-10                 [-1, 32, 69, 10]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-11                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-12                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-13                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-14                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-15                 [-1, 32, 69, 9]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-20                 [-1, 32, 69, 7]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-21                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-25                 [-1, 32, 69, 6]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-28                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-30                 [-1, 32, 69, 4]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 3]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-40                 [-1, 32, 69, 1]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 275,779
Trainable params: 275,779
Non-trainable params: 0
Total mult-adds (M): 71.72
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 11.00
Params size (MB): 1.05
Estimated Total Size (MB): 12.06
==========================================================================================
XS_torch.shape:   torch.Size([14021, 1, 69, 12])
YS_torch.shape:   torch.Size([14021, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 8  seconds  train loss: 0.41461927793801007 validation loss: 0.3485122548636204
epoch 1 time used: 8  seconds  train loss: 0.343386231298201 validation loss: 0.3143089487086142
epoch 2 time used: 9  seconds  train loss: 0.31463932195197963 validation loss: 0.2977917048499983
epoch 3 time used: 12  seconds  train loss: 0.3004709314087295 validation loss: 0.284999565964621
epoch 4 time used: 12  seconds  train loss: 0.29217597684799596 validation loss: 0.2798075137040442
epoch 5 time used: 12  seconds  train loss: 0.2847856017716902 validation loss: 0.27554471006205744
epoch 6 time used: 12  seconds  train loss: 0.27760033547042595 validation loss: 0.26904667727755466
epoch 7 time used: 12  seconds  train loss: 0.2717137607449151 validation loss: 0.26836950125792197
epoch 8 time used: 12  seconds  train loss: 0.2685348517077732 validation loss: 0.25836665519495655
epoch 9 time used: 12  seconds  train loss: 0.2644523734334318 validation loss: 0.26428931637008873
epoch 10 time used: 12  seconds  train loss: 0.26061124340268194 validation loss: 0.254690624293231
epoch 11 time used: 12  seconds  train loss: 0.25811617283856864 validation loss: 0.251288181584152
epoch 12 time used: 12  seconds  train loss: 0.25627294089007463 validation loss: 0.2515955861897994
epoch 13 time used: 12  seconds  train loss: 0.25443685726230136 validation loss: 0.2521154456184853
epoch 14 time used: 12  seconds  train loss: 0.25260812736000654 validation loss: 0.24820479766783957
epoch 15 time used: 12  seconds  train loss: 0.25093617947862634 validation loss: 0.2541379852595495
epoch 16 time used: 12  seconds  train loss: 0.2484264878776589 validation loss: 0.2471619993618265
epoch 17 time used: 12  seconds  train loss: 0.24686663889092034 validation loss: 0.25036276325251944
epoch 18 time used: 12  seconds  train loss: 0.24506269829219585 validation loss: 0.2412336256867195
epoch 19 time used: 12  seconds  train loss: 0.24461756749634328 validation loss: 0.24016016500715656
epoch 20 time used: 12  seconds  train loss: 0.2431462496557957 validation loss: 0.2381830304368047
epoch 21 time used: 12  seconds  train loss: 0.24135199350975683 validation loss: 0.2396815049175664
epoch 22 time used: 12  seconds  train loss: 0.2402251436504744 validation loss: 0.2372831376667915
epoch 23 time used: 12  seconds  train loss: 0.23901367151546757 validation loss: 0.23398719693141465
epoch 24 time used: 12  seconds  train loss: 0.23802653579864277 validation loss: 0.23472747581554562
epoch 25 time used: 12  seconds  train loss: 0.23764776606823282 validation loss: 0.23455996072707147
epoch 26 time used: 12  seconds  train loss: 0.2363707560561245 validation loss: 0.2357110079788033
epoch 27 time used: 12  seconds  train loss: 0.23517483314435492 validation loss: 0.23408234110914905
epoch 28 time used: 12  seconds  train loss: 0.23432459462376964 validation loss: 0.23332560108310485
epoch 29 time used: 12  seconds  train loss: 0.23371609416251313 validation loss: 0.23128928911393531
epoch 30 time used: 12  seconds  train loss: 0.23296469465544295 validation loss: 0.23050324938430558
epoch 31 time used: 12  seconds  train loss: 0.23132286770047603 validation loss: 0.23288859704937584
epoch 32 time used: 12  seconds  train loss: 0.23151866198169085 validation loss: 0.23063290458336191
epoch 33 time used: 12  seconds  train loss: 0.23042441784052883 validation loss: 0.23735435851900086
epoch 34 time used: 12  seconds  train loss: 0.23001876327184578 validation loss: 0.23237692288888637
epoch 35 time used: 12  seconds  train loss: 0.2286866427361868 validation loss: 0.22927180961139937
epoch 36 time used: 12  seconds  train loss: 0.22859640975786724 validation loss: 0.23226433898881715
epoch 37 time used: 12  seconds  train loss: 0.22821077823949862 validation loss: 0.2281943136242819
epoch 38 time used: 12  seconds  train loss: 0.22648582963396216 validation loss: 0.22577024465007098
epoch 39 time used: 12  seconds  train loss: 0.22657027764335144 validation loss: 0.225224879703655
epoch 40 time used: 12  seconds  train loss: 0.2254239323815889 validation loss: 0.22355836927380754
epoch 41 time used: 12  seconds  train loss: 0.22485818623777395 validation loss: 0.2214481894604764
epoch 42 time used: 12  seconds  train loss: 0.22384581683045068 validation loss: 0.2232688689871101
epoch 43 time used: 12  seconds  train loss: 0.22335913537825053 validation loss: 0.22162645729657113
epoch 44 time used: 12  seconds  train loss: 0.22355248245833012 validation loss: 0.22341857048115998
epoch 45 time used: 12  seconds  train loss: 0.22206712858390062 validation loss: 0.22356771414645793
epoch 46 time used: 12  seconds  train loss: 0.22185316905840857 validation loss: 0.22099202379150792
epoch 47 time used: 12  seconds  train loss: 0.22125889872023755 validation loss: 0.2227066031827698
epoch 48 time used: 12  seconds  train loss: 0.22072382511787864 validation loss: 0.22025845037041156
epoch 49 time used: 12  seconds  train loss: 0.22035485501199192 validation loss: 0.21968639300710055
epoch 50 time used: 12  seconds  train loss: 0.21974124070250875 validation loss: 0.21856037481845753
epoch 51 time used: 12  seconds  train loss: 0.2184781528739693 validation loss: 0.21853574886875565
epoch 52 time used: 12  seconds  train loss: 0.21798770562091246 validation loss: 0.2185749427478652
epoch 53 time used: 12  seconds  train loss: 0.2190819917156209 validation loss: 0.21811296546452397
epoch 54 time used: 12  seconds  train loss: 0.21741065972784968 validation loss: 0.21844509897644154
epoch 55 time used: 12  seconds  train loss: 0.21698836899654927 validation loss: 0.21706379500376585
epoch 56 time used: 12  seconds  train loss: 0.2174117557964381 validation loss: 0.21770877295470686
epoch 57 time used: 12  seconds  train loss: 0.21627149703470006 validation loss: 0.21847805877243257
epoch 58 time used: 12  seconds  train loss: 0.21586626999864836 validation loss: 0.2180355241127988
epoch 59 time used: 12  seconds  train loss: 0.21529401508398308 validation loss: 0.21727507706376667
epoch 60 time used: 12  seconds  train loss: 0.21473453569711518 validation loss: 0.2170598195303663
epoch 61 time used: 12  seconds  train loss: 0.2137629748760857 validation loss: 0.21672918553598527
epoch 62 time used: 12  seconds  train loss: 0.21421561732446093 validation loss: 0.21584210791760558
epoch 63 time used: 12  seconds  train loss: 0.2137715900744994 validation loss: 0.2150414671580994
epoch 64 time used: 12  seconds  train loss: 0.2131200469313672 validation loss: 0.21828913920719964
epoch 65 time used: 12  seconds  train loss: 0.21276802445006052 validation loss: 0.21353806799231972
epoch 66 time used: 12  seconds  train loss: 0.21173778086910428 validation loss: 0.2147010655078083
epoch 67 time used: 12  seconds  train loss: 0.21178101601257052 validation loss: 0.21428607340479197
epoch 68 time used: 12  seconds  train loss: 0.2106955862750749 validation loss: 0.2154978419278461
epoch 69 time used: 12  seconds  train loss: 0.21062530531512436 validation loss: 0.21525492303655683
epoch 70 time used: 12  seconds  train loss: 0.21110754377258145 validation loss: 0.21309816276285898
epoch 71 time used: 12  seconds  train loss: 0.21039753975446893 validation loss: 0.21372833791047047
epoch 72 time used: 12  seconds  train loss: 0.20956955106280936 validation loss: 0.2131606645571866
epoch 73 time used: 12  seconds  train loss: 0.20980406777260938 validation loss: 0.2119633820454053
epoch 74 time used: 12  seconds  train loss: 0.20834194076617066 validation loss: 0.21182367406228714
epoch 75 time used: 12  seconds  train loss: 0.20858220341619935 validation loss: 0.21178184859390878
epoch 76 time used: 12  seconds  train loss: 0.20760723479143137 validation loss: 0.21148279756392604
epoch 77 time used: 12  seconds  train loss: 0.20780997029783518 validation loss: 0.21041154966004835
epoch 78 time used: 12  seconds  train loss: 0.20711443139125363 validation loss: 0.21119144205290866
epoch 79 time used: 12  seconds  train loss: 0.2067327084469803 validation loss: 0.2095647500333824
epoch 80 time used: 12  seconds  train loss: 0.2065441613044574 validation loss: 0.20980958922787932
epoch 81 time used: 12  seconds  train loss: 0.20666050677253636 validation loss: 0.20913860853814562
epoch 82 time used: 12  seconds  train loss: 0.20601738418959856 validation loss: 0.20852945488279911
epoch 83 time used: 12  seconds  train loss: 0.20570104646690512 validation loss: 0.20910722454207595
epoch 84 time used: 12  seconds  train loss: 0.2056221228383207 validation loss: 0.2085915383310639
epoch 85 time used: 12  seconds  train loss: 0.2052764530276335 validation loss: 0.2077791565700864
epoch 86 time used: 12  seconds  train loss: 0.20518232029348 validation loss: 0.20953560761227583
epoch 87 time used: 12  seconds  train loss: 0.20473196888284806 validation loss: 0.20672129269708447
epoch 88 time used: 12  seconds  train loss: 0.20435045176602593 validation loss: 0.20743143152184168
epoch 89 time used: 12  seconds  train loss: 0.20385936060498272 validation loss: 0.20805602564481213
epoch 90 time used: 12  seconds  train loss: 0.20388526286058953 validation loss: 0.2063219448327338
epoch 91 time used: 12  seconds  train loss: 0.20310463585059108 validation loss: 0.20724618544560872
epoch 92 time used: 12  seconds  train loss: 0.20274097056294793 validation loss: 0.20585800456579115
epoch 93 time used: 12  seconds  train loss: 0.20244389955096498 validation loss: 0.20772576089831535
epoch 94 time used: 12  seconds  train loss: 0.20262926071153467 validation loss: 0.2053656022989335
epoch 95 time used: 12  seconds  train loss: 0.20225244027844538 validation loss: 0.2068519907139127
epoch 96 time used: 12  seconds  train loss: 0.20182362589456765 validation loss: 0.2055451295849125
epoch 97 time used: 12  seconds  train loss: 0.20183163288559244 validation loss: 0.20656263756024382
epoch 98 time used: 12  seconds  train loss: 0.2011715144327109 validation loss: 0.20611198869556682
epoch 99 time used: 12  seconds  train loss: 0.20125057629179324 validation loss: 0.20849022111141946
epoch 100 time used: 12  seconds  train loss: 0.20025763897523455 validation loss: 0.20525620304817346
epoch 101 time used: 12  seconds  train loss: 0.20109388971701872 validation loss: 0.20642674064473024
epoch 102 time used: 12  seconds  train loss: 0.2003817442995273 validation loss: 0.20568719506263733
epoch 103 time used: 12  seconds  train loss: 0.2003581407533082 validation loss: 0.20556119646233148
epoch 104 time used: 12  seconds  train loss: 0.19942546189122842 validation loss: 0.2039347684985219
epoch 105 time used: 12  seconds  train loss: 0.19952506465363043 validation loss: 0.2054853893251196
epoch 106 time used: 12  seconds  train loss: 0.19974467482868452 validation loss: 0.20374897756511257
epoch 107 time used: 12  seconds  train loss: 0.19953885657471712 validation loss: 0.20574149123886554
epoch 108 time used: 12  seconds  train loss: 0.19880602778189727 validation loss: 0.2044804301421029
epoch 109 time used: 12  seconds  train loss: 0.19810438528778423 validation loss: 0.20474925967059812
epoch 110 time used: 12  seconds  train loss: 0.19822692042225767 validation loss: 0.20631141128433955
epoch 111 time used: 12  seconds  train loss: 0.19806787630595948 validation loss: 0.204646668635432
epoch 112 time used: 12  seconds  train loss: 0.19796490506975045 validation loss: 0.2030856683297764
epoch 113 time used: 12  seconds  train loss: 0.19706505435489466 validation loss: 0.2033166077670137
epoch 114 time used: 12  seconds  train loss: 0.19727222097203753 validation loss: 0.20209545154640896
epoch 115 time used: 12  seconds  train loss: 0.19733168489873934 validation loss: 0.20163070467017544
epoch 116 time used: 12  seconds  train loss: 0.19655276136305808 validation loss: 0.20300112918010793
epoch 117 time used: 12  seconds  train loss: 0.1969516004262936 validation loss: 0.2033283598529769
epoch 118 time used: 12  seconds  train loss: 0.19663058205306977 validation loss: 0.2023513434158348
epoch 119 time used: 12  seconds  train loss: 0.19622803708027658 validation loss: 0.20279082683107885
epoch 120 time used: 12  seconds  train loss: 0.19599193885538607 validation loss: 0.203239716525698
epoch 121 time used: 12  seconds  train loss: 0.1959148587147032 validation loss: 0.2022587280918106
epoch 122 time used: 12  seconds  train loss: 0.19564192294394267 validation loss: 0.20135407098789454
epoch 123 time used: 12  seconds  train loss: 0.19545663587620252 validation loss: 0.202356053984852
epoch 124 time used: 12  seconds  train loss: 0.19551619253797564 validation loss: 0.20271045148916675
epoch 125 time used: 12  seconds  train loss: 0.19560840358106796 validation loss: 0.20388220542169475
epoch 126 time used: 12  seconds  train loss: 0.19474083182280796 validation loss: 0.20225524997547975
epoch 127 time used: 12  seconds  train loss: 0.19481766358003347 validation loss: 0.2011817022605549
epoch 128 time used: 12  seconds  train loss: 0.19461025201928395 validation loss: 0.20175222290867884
epoch 129 time used: 12  seconds  train loss: 0.19451554612729383 validation loss: 0.20072299808994812
epoch 130 time used: 12  seconds  train loss: 0.19422873094274665 validation loss: 0.20050756630731595
epoch 131 time used: 12  seconds  train loss: 0.19376122070653143 validation loss: 0.20246468238740803
epoch 132 time used: 12  seconds  train loss: 0.19384726873721367 validation loss: 0.19993644758115411
epoch 133 time used: 12  seconds  train loss: 0.19347566603292735 validation loss: 0.20048309182583504
epoch 134 time used: 12  seconds  train loss: 0.19363283460463612 validation loss: 0.20148796192489893
epoch 135 time used: 12  seconds  train loss: 0.19343587490880298 validation loss: 0.1994856153123391
epoch 136 time used: 12  seconds  train loss: 0.19289162454268502 validation loss: 0.19974574411826615
epoch 137 time used: 12  seconds  train loss: 0.19336816331813186 validation loss: 0.1998136428700674
epoch 138 time used: 12  seconds  train loss: 0.19317912644386914 validation loss: 0.20064069116482786
epoch 139 time used: 12  seconds  train loss: 0.1925879360061536 validation loss: 0.2004207629036781
epoch 140 time used: 12  seconds  train loss: 0.1921003451604271 validation loss: 0.2003807619647577
epoch 141 time used: 12  seconds  train loss: 0.19268386927866027 validation loss: 0.1997938870499628
epoch 142 time used: 12  seconds  train loss: 0.1921705331180863 validation loss: 0.1993128938363473
epoch 143 time used: 12  seconds  train loss: 0.192109144313117 validation loss: 0.19895037343960384
epoch 144 time used: 12  seconds  train loss: 0.192617321897688 validation loss: 0.2007298494194551
epoch 145 time used: 12  seconds  train loss: 0.19172490033238185 validation loss: 0.19935922703774261
epoch 146 time used: 12  seconds  train loss: 0.1919580119846308 validation loss: 0.20131418190543746
epoch 147 time used: 12  seconds  train loss: 0.19142451548580242 validation loss: 0.1988777370790856
epoch 148 time used: 12  seconds  train loss: 0.19166841730839818 validation loss: 0.1984445249106091
epoch 149 time used: 12  seconds  train loss: 0.19076735940028527 validation loss: 0.19962027765007204
epoch 150 time used: 12  seconds  train loss: 0.1914006240998723 validation loss: 0.19980550907165476
epoch 151 time used: 12  seconds  train loss: 0.19077957786175107 validation loss: 0.1993248299554764
epoch 152 time used: 12  seconds  train loss: 0.19046952381832108 validation loss: 0.19932673765262468
epoch 153 time used: 12  seconds  train loss: 0.19084819458986207 validation loss: 0.19892214261594665
epoch 154 time used: 12  seconds  train loss: 0.19062984521726384 validation loss: 0.19786712704082932
epoch 155 time used: 12  seconds  train loss: 0.19056108015287881 validation loss: 0.19804133979749217
epoch 156 time used: 12  seconds  train loss: 0.19028087897529267 validation loss: 0.19805460493359237
epoch 157 time used: 12  seconds  train loss: 0.19013148171139105 validation loss: 0.19792229565326921
epoch 158 time used: 12  seconds  train loss: 0.1898344617870214 validation loss: 0.19930894110145667
epoch 159 time used: 12  seconds  train loss: 0.1899580185280042 validation loss: 0.19908020730808812
epoch 160 time used: 12  seconds  train loss: 0.1899736152532476 validation loss: 0.198655451229825
epoch 161 time used: 12  seconds  train loss: 0.18989588958182396 validation loss: 0.19990937066669812
epoch 162 time used: 12  seconds  train loss: 0.18969401935820554 validation loss: 0.1995482369449842
epoch 163 time used: 12  seconds  train loss: 0.18937488305945718 validation loss: 0.19783130797296677
epoch 164 time used: 12  seconds  train loss: 0.18959554889942948 validation loss: 0.19751242159335053
epoch 165 time used: 12  seconds  train loss: 0.1890162334628318 validation loss: 0.1979915642748543
epoch 166 time used: 12  seconds  train loss: 0.18922958769120415 validation loss: 0.1963030651713261
epoch 167 time used: 12  seconds  train loss: 0.188744295044718 validation loss: 0.19726597517303787
epoch 168 time used: 12  seconds  train loss: 0.18862366728802865 validation loss: 0.19693943353224264
epoch 169 time used: 12  seconds  train loss: 0.18859937205002134 validation loss: 0.19638133921149928
epoch 170 time used: 12  seconds  train loss: 0.1885980554811722 validation loss: 0.1970237731440572
epoch 171 time used: 12  seconds  train loss: 0.18900306370287873 validation loss: 0.19735036590612076
epoch 172 time used: 12  seconds  train loss: 0.18848917730223055 validation loss: 0.19719178682215474
epoch 173 time used: 12  seconds  train loss: 0.188489698332725 validation loss: 0.19668647076528684
epoch 174 time used: 12  seconds  train loss: 0.18799427624416537 validation loss: 0.19815470656529877
epoch 175 time used: 12  seconds  train loss: 0.18800633430072838 validation loss: 0.1967498037859976
Early stopping at epoch: 176
YS.shape, YS_pred.shape before, (14021, 3, 69, 1) (14021, 3, 69, 1)
YS.shape, YS_pred.shape after, (14021, 3, 69) (14021, 3, 69)
YS_pred.shape before (14021, 3, 69)
YS_pred.shape after (14021, 3, 69)
YS.shape, YS_pred.shape, (14021, 3, 69) (14021, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 1.8437645893e-01, 0.1843764589
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 492.7333379835, 22.1975975723, 12.2667846761, 18.9569794862
Model Training Ended ... Sun Dec 26 17:28:51 2021
pred_METR-LA_GraphWaveNet_2112261652 testing started Sun Dec 26 17:28:51 2021
TEST XS.shape, YS.shape (3507, 1, 69, 12) (3507, 3, 69, 1)
Model Testing Started ... Sun Dec 26 17:28:51 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (3507, 3, 69, 1) (3507, 3, 69, 1)
YS.shape, YS_pred.shape after, (3507, 3, 69) (3507, 3, 69)
YS.shape, YS_pred.shape, (3507, 3, 69) (3507, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 1.9057755459e-01, 0.1905775546
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 553.5350192815, 23.5273249495, 12.8945025222, 19.4856200698
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 468.2363850715, 21.6387704150, 12.1187246512, 18.8524689952
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 551.7326492928, 23.4889899590, 12.8599300921, 19.3363791227
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 640.6355212740, 25.3107787568, 13.7048467750, 20.2680064036
Model Testing Ended ... Sun Dec 26 17:28:53 2021
