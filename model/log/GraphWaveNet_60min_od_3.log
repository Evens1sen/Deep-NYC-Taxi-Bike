data.shape (17544, 69)
pred_METR-LA_GraphWaveNet_2112262157 training started Sun Dec 26 21:57:07 2021
TRAIN XS.shape YS,shape (14021, 1, 69, 12) (14021, 3, 69, 1)
Model Training Started ... Sun Dec 26 21:57:07 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-5                  [-1, 32, 69, 12]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-7                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─linear: 3-10                 [-1, 32, 69, 10]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-11                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-12                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-13                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-14                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-15                 [-1, 32, 69, 9]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-20                 [-1, 32, 69, 7]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-21                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-25                 [-1, 32, 69, 6]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-28                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-30                 [-1, 32, 69, 4]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 3]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-40                 [-1, 32, 69, 1]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 275,779
Trainable params: 275,779
Non-trainable params: 0
Total mult-adds (M): 71.72
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 11.00
Params size (MB): 1.05
Estimated Total Size (MB): 12.06
==========================================================================================
XS_torch.shape:   torch.Size([14021, 1, 69, 12])
YS_torch.shape:   torch.Size([14021, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 13  seconds  train loss: 0.40454987214254484 validation loss: 0.33296395912213933
epoch 1 time used: 13  seconds  train loss: 0.3258139537917623 validation loss: 0.29547718539621515
epoch 2 time used: 13  seconds  train loss: 0.29241669643457757 validation loss: 0.27483941909590925
epoch 3 time used: 13  seconds  train loss: 0.27589195664519006 validation loss: 0.26049430600351015
epoch 4 time used: 13  seconds  train loss: 0.26510778631144094 validation loss: 0.262591321010693
epoch 5 time used: 13  seconds  train loss: 0.259398297422827 validation loss: 0.24974605130829677
epoch 6 time used: 13  seconds  train loss: 0.2513985010304278 validation loss: 0.24241664907079524
epoch 7 time used: 13  seconds  train loss: 0.24720342064723932 validation loss: 0.24795120922212116
epoch 8 time used: 13  seconds  train loss: 0.24419443617824782 validation loss: 0.23536485108864083
epoch 9 time used: 13  seconds  train loss: 0.2399964299105183 validation loss: 0.23455348009051286
epoch 10 time used: 13  seconds  train loss: 0.23710419629698357 validation loss: 0.2343734626897865
epoch 11 time used: 13  seconds  train loss: 0.2353417434704432 validation loss: 0.23056566756042288
epoch 12 time used: 13  seconds  train loss: 0.2323699081356066 validation loss: 0.23369659525934655
epoch 13 time used: 13  seconds  train loss: 0.23138756751236791 validation loss: 0.23519297478815113
epoch 14 time used: 13  seconds  train loss: 0.22989220634457494 validation loss: 0.2275772717974217
epoch 15 time used: 13  seconds  train loss: 0.2290696919275333 validation loss: 0.2304135994508616
epoch 16 time used: 13  seconds  train loss: 0.22867599262800986 validation loss: 0.2228823112492825
epoch 17 time used: 13  seconds  train loss: 0.22554723751303968 validation loss: 0.2241160498811936
epoch 18 time used: 13  seconds  train loss: 0.22431642432184845 validation loss: 0.2228778407054157
epoch 19 time used: 13  seconds  train loss: 0.22320158458957076 validation loss: 0.22316145739654644
epoch 20 time used: 13  seconds  train loss: 0.22271068330537158 validation loss: 0.22152541708721818
epoch 21 time used: 13  seconds  train loss: 0.22167046834542536 validation loss: 0.22234718601022255
epoch 22 time used: 13  seconds  train loss: 0.22038478590122915 validation loss: 0.22132511156426793
epoch 23 time used: 13  seconds  train loss: 0.21888968803263037 validation loss: 0.22437525277503612
epoch 24 time used: 13  seconds  train loss: 0.21819127482469283 validation loss: 0.22343062497654168
epoch 25 time used: 13  seconds  train loss: 0.2175768921555624 validation loss: 0.22010253135197788
epoch 26 time used: 13  seconds  train loss: 0.21574095427931658 validation loss: 0.22352592917387648
epoch 27 time used: 13  seconds  train loss: 0.2161203486390016 validation loss: 0.21697569043039255
epoch 28 time used: 13  seconds  train loss: 0.21525085834287688 validation loss: 0.2151657510708212
epoch 29 time used: 13  seconds  train loss: 0.2143740421024409 validation loss: 0.22036290530878275
epoch 30 time used: 13  seconds  train loss: 0.21383984310155899 validation loss: 0.21641905617693527
epoch 31 time used: 13  seconds  train loss: 0.21271687872370174 validation loss: 0.21878289254950714
epoch 32 time used: 13  seconds  train loss: 0.21315045677123023 validation loss: 0.21404405669253415
epoch 33 time used: 13  seconds  train loss: 0.21182881090164496 validation loss: 0.21775939867656977
epoch 34 time used: 13  seconds  train loss: 0.2121258595351641 validation loss: 0.2209367250467938
epoch 35 time used: 13  seconds  train loss: 0.2107720535830329 validation loss: 0.21179498415025927
epoch 36 time used: 13  seconds  train loss: 0.20924828148817137 validation loss: 0.21378924509354202
epoch 37 time used: 13  seconds  train loss: 0.20933562081840398 validation loss: 0.21561338485171302
epoch 38 time used: 13  seconds  train loss: 0.20930493192793997 validation loss: 0.211652922336197
epoch 39 time used: 13  seconds  train loss: 0.20866218688319318 validation loss: 0.21184511284656818
epoch 40 time used: 13  seconds  train loss: 0.20888453350321337 validation loss: 0.20962427995134203
epoch 41 time used: 13  seconds  train loss: 0.20799467146863057 validation loss: 0.2156461861411708
epoch 42 time used: 13  seconds  train loss: 0.20642037180024325 validation loss: 0.20888619976627168
epoch 43 time used: 13  seconds  train loss: 0.20567042181128045 validation loss: 0.20762551702979762
epoch 44 time used: 13  seconds  train loss: 0.2064268778162979 validation loss: 0.20921203886789386
epoch 45 time used: 13  seconds  train loss: 0.20517481461211062 validation loss: 0.20872885668814964
epoch 46 time used: 13  seconds  train loss: 0.20463413004965358 validation loss: 0.2092849807744698
epoch 47 time used: 13  seconds  train loss: 0.20380573298746885 validation loss: 0.20645553646295736
epoch 48 time used: 13  seconds  train loss: 0.20338795735173712 validation loss: 0.2064904409582385
epoch 49 time used: 13  seconds  train loss: 0.20395994955995086 validation loss: 0.20835062206913524
epoch 50 time used: 13  seconds  train loss: 0.20269821634753582 validation loss: 0.20714738697272603
epoch 51 time used: 13  seconds  train loss: 0.20274555718603374 validation loss: 0.2034758341207004
epoch 52 time used: 13  seconds  train loss: 0.20129750554826698 validation loss: 0.20575233261991893
epoch 53 time used: 13  seconds  train loss: 0.20154917776526324 validation loss: 0.204242689145067
epoch 54 time used: 13  seconds  train loss: 0.20085788361016416 validation loss: 0.2074046794067977
epoch 55 time used: 13  seconds  train loss: 0.20055015033392165 validation loss: 0.20424002620640716
epoch 56 time used: 13  seconds  train loss: 0.20064274060112045 validation loss: 0.20284468448134876
epoch 57 time used: 13  seconds  train loss: 0.2001446189682531 validation loss: 0.2061761681923374
epoch 58 time used: 13  seconds  train loss: 0.19924873268619825 validation loss: 0.20366462638428465
epoch 59 time used: 13  seconds  train loss: 0.1992476996280955 validation loss: 0.2067579353069892
epoch 60 time used: 13  seconds  train loss: 0.198497720750217 validation loss: 0.2042533952001157
epoch 61 time used: 13  seconds  train loss: 0.1979781451474427 validation loss: 0.20246679861580924
epoch 62 time used: 13  seconds  train loss: 0.1982555947311157 validation loss: 0.20421025618545274
epoch 63 time used: 13  seconds  train loss: 0.19736416752073327 validation loss: 0.20395334801093143
epoch 64 time used: 13  seconds  train loss: 0.19701839024386267 validation loss: 0.20859316565177133
epoch 65 time used: 13  seconds  train loss: 0.19702155338579022 validation loss: 0.20469975764759596
epoch 66 time used: 13  seconds  train loss: 0.19554638203791 validation loss: 0.2029047589589716
epoch 67 time used: 13  seconds  train loss: 0.19619137063782807 validation loss: 0.20444918108102056
epoch 68 time used: 13  seconds  train loss: 0.19481561149530938 validation loss: 0.20201785979751036
epoch 69 time used: 13  seconds  train loss: 0.1949834369868769 validation loss: 0.20278267373681
epoch 70 time used: 13  seconds  train loss: 0.19478058736293993 validation loss: 0.20114174924676104
epoch 71 time used: 13  seconds  train loss: 0.19433298002033308 validation loss: 0.20450944098587112
epoch 72 time used: 13  seconds  train loss: 0.19386193543468502 validation loss: 0.1984982933749217
epoch 73 time used: 13  seconds  train loss: 0.1936305220678259 validation loss: 0.20023002345869353
epoch 74 time used: 13  seconds  train loss: 0.19357245278681068 validation loss: 0.20066240678089248
epoch 75 time used: 13  seconds  train loss: 0.19348436604698202 validation loss: 0.19881568430018168
epoch 76 time used: 13  seconds  train loss: 0.19290003975847858 validation loss: 0.19905815100540655
epoch 77 time used: 13  seconds  train loss: 0.192040384408508 validation loss: 0.19833460751085777
epoch 78 time used: 13  seconds  train loss: 0.19206895056612763 validation loss: 0.20184572645411517
epoch 79 time used: 13  seconds  train loss: 0.19275704281781758 validation loss: 0.1982211231403329
epoch 80 time used: 13  seconds  train loss: 0.19144262046467259 validation loss: 0.19755738446594168
epoch 81 time used: 13  seconds  train loss: 0.1910414067481137 validation loss: 0.19934483021242716
epoch 82 time used: 13  seconds  train loss: 0.1905891090621768 validation loss: 0.19791260376122088
epoch 83 time used: 13  seconds  train loss: 0.19082650907136037 validation loss: 0.1969572639574137
epoch 84 time used: 13  seconds  train loss: 0.19079067760894458 validation loss: 0.20174856097169147
epoch 85 time used: 13  seconds  train loss: 0.18998237114544214 validation loss: 0.19840616644856865
epoch 86 time used: 13  seconds  train loss: 0.18979457080033846 validation loss: 0.19863610695548148
epoch 87 time used: 13  seconds  train loss: 0.18999261430664796 validation loss: 0.19565934224157283
epoch 88 time used: 13  seconds  train loss: 0.18917362859340844 validation loss: 0.1964729596598789
epoch 89 time used: 13  seconds  train loss: 0.18914275235254446 validation loss: 0.1966043380383961
epoch 90 time used: 13  seconds  train loss: 0.18815437202193971 validation loss: 0.19572920341595063
epoch 91 time used: 13  seconds  train loss: 0.18832991770940843 validation loss: 0.1970818125038778
epoch 92 time used: 13  seconds  train loss: 0.18866944809106884 validation loss: 0.1957385172707247
epoch 93 time used: 13  seconds  train loss: 0.18805928487982934 validation loss: 0.19480518009821754
epoch 94 time used: 13  seconds  train loss: 0.18764926861931533 validation loss: 0.19448806387964684
epoch 95 time used: 13  seconds  train loss: 0.18703871653003803 validation loss: 0.19938156593546347
epoch 96 time used: 13  seconds  train loss: 0.186973574643886 validation loss: 0.19489382990278384
epoch 97 time used: 13  seconds  train loss: 0.186749485574291 validation loss: 0.19821410857808297
epoch 98 time used: 13  seconds  train loss: 0.18651070639389053 validation loss: 0.19349998759325748
epoch 99 time used: 13  seconds  train loss: 0.18654401429340045 validation loss: 0.1974202599174556
epoch 100 time used: 13  seconds  train loss: 0.1854210256859733 validation loss: 0.1956410239542544
epoch 101 time used: 13  seconds  train loss: 0.18677804075645477 validation loss: 0.1933907233029859
epoch 102 time used: 13  seconds  train loss: 0.18575891127969607 validation loss: 0.19327245315210656
epoch 103 time used: 13  seconds  train loss: 0.18610866184649733 validation loss: 0.19392354430230224
epoch 104 time used: 13  seconds  train loss: 0.18587405822216435 validation loss: 0.19376847983528667
epoch 105 time used: 13  seconds  train loss: 0.18540149496186234 validation loss: 0.19519204771729518
epoch 106 time used: 13  seconds  train loss: 0.18459892959461796 validation loss: 0.1953753169883134
epoch 107 time used: 13  seconds  train loss: 0.18501993639678257 validation loss: 0.1930252577125584
epoch 108 time used: 13  seconds  train loss: 0.184231111430601 validation loss: 0.1950365154575227
epoch 109 time used: 13  seconds  train loss: 0.18402716835197347 validation loss: 0.1945133681424468
epoch 110 time used: 13  seconds  train loss: 0.18379781479006838 validation loss: 0.19394641523863068
epoch 111 time used: 13  seconds  train loss: 0.18386675201703798 validation loss: 0.19219535563717008
epoch 112 time used: 13  seconds  train loss: 0.18391216485808173 validation loss: 0.19076245196941438
epoch 113 time used: 13  seconds  train loss: 0.18322789785156118 validation loss: 0.19131792670342151
epoch 114 time used: 13  seconds  train loss: 0.18308176879079013 validation loss: 0.19249392110010724
epoch 115 time used: 13  seconds  train loss: 0.18315249618311677 validation loss: 0.19179012256218106
epoch 116 time used: 13  seconds  train loss: 0.18254092729243232 validation loss: 0.193409486075027
epoch 117 time used: 13  seconds  train loss: 0.1826121843537485 validation loss: 0.19343271838789047
epoch 118 time used: 13  seconds  train loss: 0.18265052491517808 validation loss: 0.1933928445296089
epoch 119 time used: 13  seconds  train loss: 0.18238356619597182 validation loss: 0.1923721183879812
epoch 120 time used: 13  seconds  train loss: 0.18231457280906668 validation loss: 0.19228009679830216
epoch 121 time used: 13  seconds  train loss: 0.18147661685846433 validation loss: 0.1909869774385513
epoch 122 time used: 13  seconds  train loss: 0.18139157628620492 validation loss: 0.18970224886061599
epoch 123 time used: 13  seconds  train loss: 0.18151936376662298 validation loss: 0.1912243739153002
epoch 124 time used: 13  seconds  train loss: 0.18168026192358505 validation loss: 0.19093472652957566
epoch 125 time used: 13  seconds  train loss: 0.18165369629179728 validation loss: 0.19114433611486548
epoch 126 time used: 13  seconds  train loss: 0.18059525164381704 validation loss: 0.18997153539488945
epoch 127 time used: 13  seconds  train loss: 0.180710524485793 validation loss: 0.1912912898024898
epoch 128 time used: 13  seconds  train loss: 0.18116293944731807 validation loss: 0.191824029869715
epoch 129 time used: 13  seconds  train loss: 0.18109339484377096 validation loss: 0.19134180905712855
epoch 130 time used: 13  seconds  train loss: 0.1806175606449769 validation loss: 0.18940041256304543
epoch 131 time used: 13  seconds  train loss: 0.18001496806901093 validation loss: 0.19180988910976166
epoch 132 time used: 13  seconds  train loss: 0.18074283430387425 validation loss: 0.1891582092505078
epoch 133 time used: 13  seconds  train loss: 0.17962467538288218 validation loss: 0.1909021007474055
epoch 134 time used: 13  seconds  train loss: 0.18011603021236908 validation loss: 0.19163426346290607
epoch 135 time used: 13  seconds  train loss: 0.17969948097086902 validation loss: 0.18872530745630325
epoch 136 time used: 13  seconds  train loss: 0.17881680437629993 validation loss: 0.19082710217457122
epoch 137 time used: 13  seconds  train loss: 0.18114701735495278 validation loss: 0.18837774318419248
epoch 138 time used: 13  seconds  train loss: 0.17902083535574528 validation loss: 0.18842003828990955
epoch 139 time used: 13  seconds  train loss: 0.1792537190595822 validation loss: 0.18977677945368507
epoch 140 time used: 13  seconds  train loss: 0.17861823398008927 validation loss: 0.18814948953462884
epoch 141 time used: 13  seconds  train loss: 0.17859312419709453 validation loss: 0.188697484727254
epoch 142 time used: 13  seconds  train loss: 0.17923884504794452 validation loss: 0.18833579148521304
epoch 143 time used: 13  seconds  train loss: 0.17806421795068597 validation loss: 0.18803560723594714
epoch 144 time used: 13  seconds  train loss: 0.17867435806925536 validation loss: 0.1898347263889046
epoch 145 time used: 13  seconds  train loss: 0.17813375642274776 validation loss: 0.18920978685310752
epoch 146 time used: 13  seconds  train loss: 0.1785619662577219 validation loss: 0.18836338734769575
epoch 147 time used: 13  seconds  train loss: 0.17866682349897028 validation loss: 0.18814470720542747
epoch 148 time used: 13  seconds  train loss: 0.17860848951949956 validation loss: 0.1878830504992045
epoch 149 time used: 13  seconds  train loss: 0.17720691849033335 validation loss: 0.18758925825306436
epoch 150 time used: 13  seconds  train loss: 0.17721374467486545 validation loss: 0.18683800457446015
epoch 151 time used: 13  seconds  train loss: 0.17791260618571936 validation loss: 0.19225536491689993
epoch 152 time used: 13  seconds  train loss: 0.17712305355993202 validation loss: 0.1893414548394752
epoch 153 time used: 13  seconds  train loss: 0.17700123337510745 validation loss: 0.18917116116470972
epoch 154 time used: 13  seconds  train loss: 0.17684788337778415 validation loss: 0.1877904981629752
epoch 155 time used: 13  seconds  train loss: 0.17681954600910507 validation loss: 0.18664641309416913
epoch 156 time used: 11  seconds  train loss: 0.17652197296354333 validation loss: 0.18855656225274647
epoch 157 time used: 9  seconds  train loss: 0.17711082612958995 validation loss: 0.19387245066017678
epoch 158 time used: 8  seconds  train loss: 0.17712656916995215 validation loss: 0.18811294998329706
epoch 159 time used: 9  seconds  train loss: 0.17613574543759533 validation loss: 0.18676964367415247
epoch 160 time used: 8  seconds  train loss: 0.1775527618385737 validation loss: 0.1875186856056171
epoch 161 time used: 9  seconds  train loss: 0.1767240255041079 validation loss: 0.189454606768749
epoch 162 time used: 9  seconds  train loss: 0.1766625261332027 validation loss: 0.1893504286961629
epoch 163 time used: 8  seconds  train loss: 0.1761444735729154 validation loss: 0.18713377887904814
epoch 164 time used: 9  seconds  train loss: 0.17582348415176838 validation loss: 0.18789161428069634
Early stopping at epoch: 165
YS.shape, YS_pred.shape before, (14021, 3, 69, 1) (14021, 3, 69, 1)
YS.shape, YS_pred.shape after, (14021, 3, 69) (14021, 3, 69)
YS_pred.shape before (14021, 3, 69)
YS_pred.shape after (14021, 3, 69)
YS.shape, YS_pred.shape, (14021, 3, 69) (14021, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 1.7320357745e-01, 0.1732035774
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 361.4398084171, 19.0115703827, 10.9873706261, 17.2482168971
Model Training Ended ... Sun Dec 26 22:34:13 2021
pred_METR-LA_GraphWaveNet_2112262157 testing started Sun Dec 26 22:34:13 2021
TEST XS.shape, YS.shape (3507, 1, 69, 12) (3507, 3, 69, 1)
Model Testing Started ... Sun Dec 26 22:34:13 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (3507, 3, 69, 1) (3507, 3, 69, 1)
YS.shape, YS_pred.shape after, (3507, 3, 69) (3507, 3, 69)
YS.shape, YS_pred.shape, (3507, 3, 69) (3507, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 1.8119177983e-01, 0.1811917798
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 399.4873585621, 19.9871798551, 11.4409177761, 18.4783614372
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 330.4725858829, 18.1789049693, 10.8775687343, 18.6027935196
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 400.3228594491, 20.0080698582, 11.4347454523, 18.3553662644
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 467.6657419732, 21.6255807315, 12.0104327241, 18.4769276691
Model Testing Ended ... Sun Dec 26 22:34:15 2021
