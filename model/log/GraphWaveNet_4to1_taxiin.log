data.shape (35088, 69, 4)
pred_METR-LA_GraphWaveNet_2112251807 training started Sat Dec 25 18:07:40 2021
TRAIN XS.shape YS,shape (28056, 4, 69, 12) (28056, 3, 69, 1)
Model Training Started ... Sat Dec 25 18:07:40 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          160
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-5                  [-1, 32, 69, 12]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-7                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─linear: 3-10                 [-1, 32, 69, 10]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-11                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-12                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-13                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-14                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-15                 [-1, 32, 69, 9]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-20                 [-1, 32, 69, 7]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-21                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-25                 [-1, 32, 69, 6]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-28                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-30                 [-1, 32, 69, 4]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 3]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-40                 [-1, 32, 69, 1]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 275,875
Trainable params: 275,875
Non-trainable params: 0
Total mult-adds (M): 71.81
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 11.00
Params size (MB): 1.05
Estimated Total Size (MB): 12.07
==========================================================================================
XS_torch.shape:   torch.Size([28056, 4, 69, 12])
YS_torch.shape:   torch.Size([28056, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 18  seconds  train loss: 0.3053944240682669 validation loss: 0.09349545636746766
epoch 1 time used: 20  seconds  train loss: 0.26466802685822804 validation loss: 0.08233107991850135
epoch 2 time used: 18  seconds  train loss: 0.2512657070209443 validation loss: 0.0892903189229802
epoch 3 time used: 17  seconds  train loss: 0.2443642370322993 validation loss: 0.07744730967791426
epoch 4 time used: 17  seconds  train loss: 0.2386419583208969 validation loss: 0.07821102333495444
epoch 5 time used: 16  seconds  train loss: 0.23377762826910678 validation loss: 0.07758395506814228
epoch 6 time used: 16  seconds  train loss: 0.23076430508619783 validation loss: 0.07623992266097843
epoch 7 time used: 17  seconds  train loss: 0.227653338158877 validation loss: 0.07772050688528151
epoch 8 time used: 16  seconds  train loss: 0.22589836410409958 validation loss: 0.07482168465504321
epoch 9 time used: 16  seconds  train loss: 0.22385435886740263 validation loss: 0.07871451814366026
epoch 10 time used: 18  seconds  train loss: 0.22226946171036396 validation loss: 0.07453605908893064
epoch 11 time used: 17  seconds  train loss: 0.22111082876683777 validation loss: 0.07433230836727288
epoch 12 time used: 19  seconds  train loss: 0.21993604813376105 validation loss: 0.07952560723626718
epoch 13 time used: 17  seconds  train loss: 0.21874543902339738 validation loss: 0.07359050748599436
epoch 14 time used: 16  seconds  train loss: 0.21769695689289326 validation loss: 0.07716340223438284
epoch 15 time used: 16  seconds  train loss: 0.2160269803283676 validation loss: 0.07761424523891124
epoch 16 time used: 17  seconds  train loss: 0.21569547440773687 validation loss: 0.073607675474119
epoch 17 time used: 16  seconds  train loss: 0.21515306459895422 validation loss: 0.07899472993350552
epoch 18 time used: 16  seconds  train loss: 0.21450258246424378 validation loss: 0.07369381913796837
epoch 19 time used: 16  seconds  train loss: 0.2137600996152287 validation loss: 0.07348490555698728
epoch 20 time used: 16  seconds  train loss: 0.2134064424377366 validation loss: 0.074820108348432
epoch 21 time used: 14  seconds  train loss: 0.21216084619426276 validation loss: 0.07213784368894091
epoch 22 time used: 16  seconds  train loss: 0.21188707422508943 validation loss: 0.07168899019763175
epoch 23 time used: 17  seconds  train loss: 0.21132340167873945 validation loss: 0.07500739072483763
epoch 24 time used: 16  seconds  train loss: 0.21064773070284867 validation loss: 0.07578924140012057
epoch 25 time used: 16  seconds  train loss: 0.21034521086222577 validation loss: 0.07286337909023409
epoch 26 time used: 15  seconds  train loss: 0.2099166906630465 validation loss: 0.07278072159914743
epoch 27 time used: 17  seconds  train loss: 0.20934307694743473 validation loss: 0.07244008083330929
epoch 28 time used: 20  seconds  train loss: 0.20902409807288858 validation loss: 0.07241271206557258
epoch 29 time used: 20  seconds  train loss: 0.208677382619761 validation loss: 0.07394117063178546
epoch 30 time used: 17  seconds  train loss: 0.20816920855083293 validation loss: 0.0719013328175107
epoch 31 time used: 16  seconds  train loss: 0.2076372548150523 validation loss: 0.07324719461733234
epoch 32 time used: 16  seconds  train loss: 0.2073993146440163 validation loss: 0.07158282174406685
epoch 33 time used: 20  seconds  train loss: 0.2068486924270801 validation loss: 0.07401132450200297
epoch 34 time used: 20  seconds  train loss: 0.20647975327385978 validation loss: 0.07509785099419768
epoch 35 time used: 20  seconds  train loss: 0.20665799882439734 validation loss: 0.07233412285705289
epoch 36 time used: 20  seconds  train loss: 0.20592131054645654 validation loss: 0.07505051765111834
epoch 37 time used: 18  seconds  train loss: 0.20536982968538822 validation loss: 0.07216436191564753
epoch 38 time used: 16  seconds  train loss: 0.20533793150062662 validation loss: 0.07220232556408071
epoch 39 time used: 16  seconds  train loss: 0.20521265156092122 validation loss: 0.07259176921344802
epoch 40 time used: 17  seconds  train loss: 0.20490372291533512 validation loss: 0.07465256542383791
epoch 41 time used: 17  seconds  train loss: 0.20435207931785324 validation loss: 0.07240002092674039
Early stopping at epoch: 42
YS.shape, YS_pred.shape before, (28056, 3, 69, 1) (28056, 3, 69, 1)
YS.shape, YS_pred.shape after, (28056, 3, 69) (28056, 3, 69)
YS_pred.shape before (28056, 3, 69)
YS_pred.shape after (28056, 3, 69)
YS.shape, YS_pred.shape, (28056, 3, 69) (28056, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 2.0274602450e-01, 0.2027460245
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 127.0047919512, 11.2696402760, 6.2672944480, 42.5422561942
Model Training Ended ... Sat Dec 25 18:20:29 2021
pred_METR-LA_GraphWaveNet_2112251807 testing started Sat Dec 25 18:20:29 2021
TEST XS.shape, YS.shape (7016, 4, 69, 12) (7016, 3, 69, 1)
Model Testing Started ... Sat Dec 25 18:20:29 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (7016, 3, 69, 1) (7016, 3, 69, 1)
YS.shape, YS_pred.shape after, (7016, 3, 69) (7016, 3, 69)
YS.shape, YS_pred.shape, (7016, 3, 69) (7016, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 1.1177745011e-01, 0.1117774501
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 51.1849468145, 7.1543655774, 4.1151060205, 83.0817558357
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 36.8695623288, 6.0720311535, 3.6043147199, 74.9230529822
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 49.6533368208, 7.0465123870, 4.0797192578, 83.3171799628
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 67.0328652007, 8.1873600874, 4.6613161481, 91.0055162738
Model Testing Ended ... Sat Dec 25 18:20:31 2021
