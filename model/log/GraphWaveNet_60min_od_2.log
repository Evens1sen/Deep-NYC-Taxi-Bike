data.shape (17544, 69)
pred_METR-LA_GraphWaveNet_2112262156 training started Sun Dec 26 21:56:49 2021
TRAIN XS.shape YS,shape (14021, 1, 69, 12) (14021, 3, 69, 1)
Model Training Started ... Sun Dec 26 21:56:49 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-5                  [-1, 32, 69, 12]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-7                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─linear: 3-10                 [-1, 32, 69, 10]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-11                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-12                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-13                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-14                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-15                 [-1, 32, 69, 9]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-20                 [-1, 32, 69, 7]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-21                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-25                 [-1, 32, 69, 6]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-28                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-30                 [-1, 32, 69, 4]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 3]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-40                 [-1, 32, 69, 1]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 275,779
Trainable params: 275,779
Non-trainable params: 0
Total mult-adds (M): 71.72
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 11.00
Params size (MB): 1.05
Estimated Total Size (MB): 12.06
==========================================================================================
XS_torch.shape:   torch.Size([14021, 1, 69, 12])
YS_torch.shape:   torch.Size([14021, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 9  seconds  train loss: 0.4146886307407288 validation loss: 0.3390975149780835
epoch 1 time used: 9  seconds  train loss: 0.3384226713539686 validation loss: 0.30961166686897473
epoch 2 time used: 13  seconds  train loss: 0.3095146030197324 validation loss: 0.2881706298689671
epoch 3 time used: 13  seconds  train loss: 0.29388463983016483 validation loss: 0.2782941741121883
epoch 4 time used: 13  seconds  train loss: 0.28276187865556085 validation loss: 0.27386616019949667
epoch 5 time used: 13  seconds  train loss: 0.27641923230519155 validation loss: 0.26936580216925415
epoch 6 time used: 13  seconds  train loss: 0.2686489216854567 validation loss: 0.25795652179703055
epoch 7 time used: 13  seconds  train loss: 0.26436372363182553 validation loss: 0.25948848308866795
epoch 8 time used: 13  seconds  train loss: 0.2623447144618437 validation loss: 0.25105301371929106
epoch 9 time used: 13  seconds  train loss: 0.25797183978312715 validation loss: 0.2540975428620407
epoch 10 time used: 13  seconds  train loss: 0.2542614092996309 validation loss: 0.24813943963627508
epoch 11 time used: 13  seconds  train loss: 0.2518940866576525 validation loss: 0.24597512155822257
epoch 12 time used: 13  seconds  train loss: 0.25077602867295773 validation loss: 0.24559220846761518
epoch 13 time used: 13  seconds  train loss: 0.24880571840716606 validation loss: 0.24536228062626436
epoch 14 time used: 13  seconds  train loss: 0.24687032609021659 validation loss: 0.24204560390079083
epoch 15 time used: 13  seconds  train loss: 0.24589969225550926 validation loss: 0.24729758852968473
epoch 16 time used: 13  seconds  train loss: 0.24391884422084584 validation loss: 0.2425602998518631
epoch 17 time used: 13  seconds  train loss: 0.24324200476541324 validation loss: 0.2406793276174233
epoch 18 time used: 13  seconds  train loss: 0.24088260058688932 validation loss: 0.23858398969215594
epoch 19 time used: 13  seconds  train loss: 0.24076739265994915 validation loss: 0.2376267431432427
epoch 20 time used: 13  seconds  train loss: 0.23959109472808676 validation loss: 0.23408986119733016
epoch 21 time used: 13  seconds  train loss: 0.2382698973897695 validation loss: 0.2359442942511743
epoch 22 time used: 13  seconds  train loss: 0.2368850421062074 validation loss: 0.23204443377218992
epoch 23 time used: 13  seconds  train loss: 0.2359290657668849 validation loss: 0.2333111542585708
epoch 24 time used: 13  seconds  train loss: 0.2349866183749775 validation loss: 0.23478256265435707
epoch 25 time used: 13  seconds  train loss: 0.23451760783913006 validation loss: 0.23282915683589658
epoch 26 time used: 13  seconds  train loss: 0.2333994225216565 validation loss: 0.23369842443851083
epoch 27 time used: 13  seconds  train loss: 0.23256635266521056 validation loss: 0.23165740183232106
epoch 28 time used: 13  seconds  train loss: 0.23218482528713888 validation loss: 0.23034185580845498
epoch 29 time used: 13  seconds  train loss: 0.23093798946568583 validation loss: 0.22936256165274604
epoch 30 time used: 13  seconds  train loss: 0.23113299283388192 validation loss: 0.23079571238396443
epoch 31 time used: 13  seconds  train loss: 0.2288450718625656 validation loss: 0.22904039718767472
epoch 32 time used: 13  seconds  train loss: 0.2291819671145238 validation loss: 0.22917371538626555
epoch 33 time used: 13  seconds  train loss: 0.22887846557857705 validation loss: 0.2337940090802895
epoch 34 time used: 13  seconds  train loss: 0.2283640924244779 validation loss: 0.23430758711275754
epoch 35 time used: 13  seconds  train loss: 0.22650288986020886 validation loss: 0.22552137144007686
epoch 36 time used: 13  seconds  train loss: 0.2261276495137975 validation loss: 0.23178479044830466
epoch 37 time used: 13  seconds  train loss: 0.2255732811231896 validation loss: 0.22767615886123535
epoch 38 time used: 13  seconds  train loss: 0.22458484427797548 validation loss: 0.22539670325930433
epoch 39 time used: 13  seconds  train loss: 0.2239652719478635 validation loss: 0.22580685988026078
epoch 40 time used: 13  seconds  train loss: 0.22450943435000253 validation loss: 0.22194179868738922
epoch 41 time used: 13  seconds  train loss: 0.22300886436398037 validation loss: 0.22099264552609552
epoch 42 time used: 13  seconds  train loss: 0.22240681408922408 validation loss: 0.22152595970029498
epoch 43 time used: 13  seconds  train loss: 0.22130970860930735 validation loss: 0.2210476312699212
epoch 44 time used: 13  seconds  train loss: 0.22214240439170574 validation loss: 0.22125472323899942
epoch 45 time used: 13  seconds  train loss: 0.2201825630783374 validation loss: 0.22012510664518806
epoch 46 time used: 13  seconds  train loss: 0.22027570348358091 validation loss: 0.2201825504090809
epoch 47 time used: 13  seconds  train loss: 0.2194697753318871 validation loss: 0.22041705407146991
epoch 48 time used: 13  seconds  train loss: 0.219438097989633 validation loss: 0.2201166048824481
epoch 49 time used: 13  seconds  train loss: 0.21936180000201008 validation loss: 0.2212017040489336
epoch 50 time used: 13  seconds  train loss: 0.21878872668953023 validation loss: 0.21914175593098165
epoch 51 time used: 13  seconds  train loss: 0.2172165600929736 validation loss: 0.2179699164931596
epoch 52 time used: 13  seconds  train loss: 0.21710451993329696 validation loss: 0.21910497668601414
epoch 53 time used: 13  seconds  train loss: 0.216515574343126 validation loss: 0.21742464561191752
epoch 54 time used: 13  seconds  train loss: 0.21571773013211168 validation loss: 0.2187652273121658
epoch 55 time used: 13  seconds  train loss: 0.2153861286209117 validation loss: 0.21602299012120493
epoch 56 time used: 13  seconds  train loss: 0.21605572673875656 validation loss: 0.21649407939236298
epoch 57 time used: 13  seconds  train loss: 0.21461404461618896 validation loss: 0.21855467078485832
epoch 58 time used: 13  seconds  train loss: 0.21427484755023202 validation loss: 0.2190796387532202
epoch 59 time used: 13  seconds  train loss: 0.21414880081403906 validation loss: 0.21575389719152205
epoch 60 time used: 13  seconds  train loss: 0.21316299087786697 validation loss: 0.21587006497811537
epoch 61 time used: 13  seconds  train loss: 0.2121869902833106 validation loss: 0.21506990264533793
epoch 62 time used: 13  seconds  train loss: 0.21280201413478297 validation loss: 0.215126593122806
epoch 63 time used: 13  seconds  train loss: 0.21185486161498943 validation loss: 0.214314941068207
epoch 64 time used: 13  seconds  train loss: 0.21105756171662293 validation loss: 0.21548467133294089
epoch 65 time used: 13  seconds  train loss: 0.21107041087568798 validation loss: 0.21361415071175974
epoch 66 time used: 13  seconds  train loss: 0.2101782586876173 validation loss: 0.21581478958393735
epoch 67 time used: 13  seconds  train loss: 0.21028686327696391 validation loss: 0.21633774269939626
epoch 68 time used: 13  seconds  train loss: 0.2094542762725564 validation loss: 0.21554723887768598
epoch 69 time used: 13  seconds  train loss: 0.20924188497888951 validation loss: 0.21759146900769988
epoch 70 time used: 13  seconds  train loss: 0.20898490560183045 validation loss: 0.2124476581811905
epoch 71 time used: 13  seconds  train loss: 0.20901425991767308 validation loss: 0.2141088593859572
epoch 72 time used: 13  seconds  train loss: 0.20806166734686107 validation loss: 0.21527140214826743
epoch 73 time used: 13  seconds  train loss: 0.20811651074268314 validation loss: 0.21270614658432965
epoch 74 time used: 13  seconds  train loss: 0.20750839836752139 validation loss: 0.21215202053716642
epoch 75 time used: 13  seconds  train loss: 0.20727160627907248 validation loss: 0.21108864690668572
epoch 76 time used: 13  seconds  train loss: 0.20661639185809996 validation loss: 0.2112248486457249
epoch 77 time used: 13  seconds  train loss: 0.20607449510294176 validation loss: 0.21030827016233378
epoch 78 time used: 13  seconds  train loss: 0.20610989644312105 validation loss: 0.2128084316314185
epoch 79 time used: 13  seconds  train loss: 0.2062816351486955 validation loss: 0.2091269305499703
epoch 80 time used: 13  seconds  train loss: 0.20542656033405232 validation loss: 0.20918724897141736
epoch 81 time used: 13  seconds  train loss: 0.20523138704306146 validation loss: 0.20964464487447373
epoch 82 time used: 13  seconds  train loss: 0.20439771969717957 validation loss: 0.20883637493294577
epoch 83 time used: 13  seconds  train loss: 0.2051787978717781 validation loss: 0.20934751044153418
epoch 84 time used: 13  seconds  train loss: 0.2041142361246494 validation loss: 0.2107212267820317
epoch 85 time used: 13  seconds  train loss: 0.20380199697435894 validation loss: 0.20865965722563332
epoch 86 time used: 13  seconds  train loss: 0.2034486967294116 validation loss: 0.20900203561313616
epoch 87 time used: 13  seconds  train loss: 0.20312286971697482 validation loss: 0.21019219243723666
epoch 88 time used: 13  seconds  train loss: 0.20282621456739527 validation loss: 0.20662749191045898
epoch 89 time used: 13  seconds  train loss: 0.20278725615922116 validation loss: 0.2071001217304742
epoch 90 time used: 13  seconds  train loss: 0.20224056215814087 validation loss: 0.20632799954939351
epoch 91 time used: 13  seconds  train loss: 0.20189661065977094 validation loss: 0.2079206947099122
epoch 92 time used: 13  seconds  train loss: 0.20130361274083974 validation loss: 0.2084804550365795
epoch 93 time used: 13  seconds  train loss: 0.20188296312496024 validation loss: 0.2072683583564644
epoch 94 time used: 13  seconds  train loss: 0.20130424341414627 validation loss: 0.20971530675888062
epoch 95 time used: 13  seconds  train loss: 0.20062738828990215 validation loss: 0.20784159298801314
epoch 96 time used: 13  seconds  train loss: 0.20040684425368308 validation loss: 0.20576421845931703
epoch 97 time used: 13  seconds  train loss: 0.20022810686575226 validation loss: 0.2066109761621227
epoch 98 time used: 13  seconds  train loss: 0.1994987378242469 validation loss: 0.2061564114286909
epoch 99 time used: 13  seconds  train loss: 0.19985068876346082 validation loss: 0.20792025315781967
epoch 100 time used: 13  seconds  train loss: 0.1989789244199289 validation loss: 0.20554999405325852
epoch 101 time used: 13  seconds  train loss: 0.20001329887290323 validation loss: 0.20418036334254847
epoch 102 time used: 13  seconds  train loss: 0.19923336768931585 validation loss: 0.20534740101080654
epoch 103 time used: 13  seconds  train loss: 0.19935615185829184 validation loss: 0.20649971943444276
epoch 104 time used: 13  seconds  train loss: 0.1991800176113951 validation loss: 0.20537962356058448
epoch 105 time used: 13  seconds  train loss: 0.19854788145491928 validation loss: 0.20560673697805376
epoch 106 time used: 13  seconds  train loss: 0.19810865602763034 validation loss: 0.20320744224262455
epoch 107 time used: 13  seconds  train loss: 0.19823947287476487 validation loss: 0.20377426620421923
epoch 108 time used: 13  seconds  train loss: 0.19740218716061073 validation loss: 0.20490272429012532
epoch 109 time used: 13  seconds  train loss: 0.19719593119535767 validation loss: 0.20438874140169302
epoch 110 time used: 13  seconds  train loss: 0.1970174871567293 validation loss: 0.20645138866141124
epoch 111 time used: 13  seconds  train loss: 0.19732357343439563 validation loss: 0.20617072967651975
epoch 112 time used: 13  seconds  train loss: 0.19733981409677667 validation loss: 0.20255635858976154
epoch 113 time used: 13  seconds  train loss: 0.19653647329584176 validation loss: 0.20436972057520153
epoch 114 time used: 13  seconds  train loss: 0.19619683344627695 validation loss: 0.20277813746802684
epoch 115 time used: 13  seconds  train loss: 0.19638692199659144 validation loss: 0.2032384720959802
epoch 116 time used: 13  seconds  train loss: 0.19551644617838 validation loss: 0.2023119113646571
epoch 117 time used: 13  seconds  train loss: 0.19609034409303794 validation loss: 0.20472695405185393
epoch 118 time used: 13  seconds  train loss: 0.19532745098558513 validation loss: 0.20442775123913628
epoch 119 time used: 13  seconds  train loss: 0.19520783853387072 validation loss: 0.20244934381380533
epoch 120 time used: 13  seconds  train loss: 0.19532212123328246 validation loss: 0.2030499052283972
epoch 121 time used: 13  seconds  train loss: 0.19539468952390554 validation loss: 0.20151182024803968
epoch 122 time used: 13  seconds  train loss: 0.19465527739126828 validation loss: 0.20284034962050246
epoch 123 time used: 13  seconds  train loss: 0.19520661498188857 validation loss: 0.20367603528452002
epoch 124 time used: 13  seconds  train loss: 0.1945390788844948 validation loss: 0.20230058466306905
epoch 125 time used: 13  seconds  train loss: 0.1946248981165194 validation loss: 0.20260114946572086
epoch 126 time used: 13  seconds  train loss: 0.1937728091360188 validation loss: 0.20137046235021155
epoch 127 time used: 13  seconds  train loss: 0.1940332410786025 validation loss: 0.20064303633388764
epoch 128 time used: 13  seconds  train loss: 0.1936482787326605 validation loss: 0.20125578702584174
epoch 129 time used: 13  seconds  train loss: 0.19407659517385534 validation loss: 0.20051194008288897
epoch 130 time used: 13  seconds  train loss: 0.19347078286847424 validation loss: 0.2002309794281118
epoch 131 time used: 13  seconds  train loss: 0.19314774898080356 validation loss: 0.2027349274412129
epoch 132 time used: 13  seconds  train loss: 0.19354513302605744 validation loss: 0.20080606512729604
epoch 133 time used: 13  seconds  train loss: 0.19246983045197716 validation loss: 0.20010123494959395
epoch 134 time used: 13  seconds  train loss: 0.1931413106588731 validation loss: 0.20106817788725503
epoch 135 time used: 13  seconds  train loss: 0.19244999751171693 validation loss: 0.20007787961927198
epoch 136 time used: 13  seconds  train loss: 0.19218042773204633 validation loss: 0.20104074799463673
epoch 137 time used: 13  seconds  train loss: 0.1923280719207326 validation loss: 0.20051071237341309
epoch 138 time used: 13  seconds  train loss: 0.1919695897884776 validation loss: 0.19950323335558634
epoch 139 time used: 13  seconds  train loss: 0.19209277890756227 validation loss: 0.1992812639413666
epoch 140 time used: 13  seconds  train loss: 0.1915786414172465 validation loss: 0.20117990875747363
epoch 141 time used: 13  seconds  train loss: 0.19232254883715957 validation loss: 0.19892094543982558
epoch 142 time used: 13  seconds  train loss: 0.19174375122441584 validation loss: 0.2003738355174176
epoch 143 time used: 13  seconds  train loss: 0.19166618419424267 validation loss: 0.19847574881907537
epoch 144 time used: 13  seconds  train loss: 0.19183595477077134 validation loss: 0.1998855983673744
epoch 145 time used: 13  seconds  train loss: 0.1911691979453196 validation loss: 0.19843103283993938
epoch 146 time used: 13  seconds  train loss: 0.19173998855732147 validation loss: 0.20319736133081465
epoch 147 time used: 13  seconds  train loss: 0.1907689000112753 validation loss: 0.1988657728747103
epoch 148 time used: 13  seconds  train loss: 0.19101468153251744 validation loss: 0.1984887150309117
epoch 149 time used: 13  seconds  train loss: 0.19006704566997235 validation loss: 0.19880710770012106
epoch 150 time used: 13  seconds  train loss: 0.19020373424995518 validation loss: 0.1992997972797273
epoch 151 time used: 13  seconds  train loss: 0.1897909473305927 validation loss: 0.20031590576146033
epoch 152 time used: 13  seconds  train loss: 0.19003192953617207 validation loss: 0.19949200153520838
epoch 153 time used: 13  seconds  train loss: 0.18991375569027022 validation loss: 0.19934424502096104
epoch 154 time used: 13  seconds  train loss: 0.1900852990142678 validation loss: 0.1989660417768388
Early stopping at epoch: 155
YS.shape, YS_pred.shape before, (14021, 3, 69, 1) (14021, 3, 69, 1)
YS.shape, YS_pred.shape after, (14021, 3, 69) (14021, 3, 69)
YS_pred.shape before (14021, 3, 69)
YS_pred.shape after (14021, 3, 69)
YS.shape, YS_pred.shape, (14021, 3, 69) (14021, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 1.8602825809e-01, 0.1860282581
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 505.5533784081, 22.4845141911, 12.5254355408, 18.9297333928
Model Training Ended ... Sun Dec 26 22:32:41 2021
pred_METR-LA_GraphWaveNet_2112262156 testing started Sun Dec 26 22:32:41 2021
TEST XS.shape, YS.shape (3507, 1, 69, 12) (3507, 3, 69, 1)
Model Testing Started ... Sun Dec 26 22:32:41 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (3507, 3, 69, 1) (3507, 3, 69, 1)
YS.shape, YS_pred.shape after, (3507, 3, 69) (3507, 3, 69)
YS.shape, YS_pred.shape, (3507, 3, 69) (3507, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 1.9272466115e-01, 0.1927246611
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 569.9935619625, 23.8745379424, 13.0777024061, 19.6927850397
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 484.6759749016, 22.0153577055, 12.2721880110, 18.8397332706
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 574.1256976961, 23.9609202181, 13.1075873728, 19.7128682287
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 651.1784521109, 25.5181984496, 13.8533250053, 20.5257452686
Model Testing Ended ... Sun Dec 26 22:32:44 2021
