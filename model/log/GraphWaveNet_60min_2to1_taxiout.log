data.shape (17544, 69, 2)
pred_METR-LA_GraphWaveNet_2112262144 training started Sun Dec 26 21:44:27 2021
TRAIN XS.shape YS,shape (14021, 2, 69, 12) (14021, 3, 69, 1)
Model Training Started ... Sun Dec 26 21:44:28 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          96
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-5                  [-1, 32, 69, 12]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-7                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─linear: 3-10                 [-1, 32, 69, 10]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-11                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-12                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-13                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-14                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-15                 [-1, 32, 69, 9]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-20                 [-1, 32, 69, 7]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-21                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-25                 [-1, 32, 69, 6]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-28                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-30                 [-1, 32, 69, 4]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 3]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-40                 [-1, 32, 69, 1]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 275,811
Trainable params: 275,811
Non-trainable params: 0
Total mult-adds (M): 71.75
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 11.00
Params size (MB): 1.05
Estimated Total Size (MB): 12.06
==========================================================================================
XS_torch.shape:   torch.Size([14021, 2, 69, 12])
YS_torch.shape:   torch.Size([14021, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 12  seconds  train loss: 0.3903145399570154 validation loss: 0.34433520023848624
epoch 1 time used: 12  seconds  train loss: 0.3211423118902722 validation loss: 0.29459911193836774
epoch 2 time used: 12  seconds  train loss: 0.2948897666658296 validation loss: 0.278923468731229
epoch 3 time used: 12  seconds  train loss: 0.28006959015902533 validation loss: 0.27684675705344486
epoch 4 time used: 12  seconds  train loss: 0.27001801690916927 validation loss: 0.2688886300876898
epoch 5 time used: 12  seconds  train loss: 0.2636162337823065 validation loss: 0.25630333197674476
epoch 6 time used: 12  seconds  train loss: 0.2587468745772987 validation loss: 0.25643704754246754
epoch 7 time used: 12  seconds  train loss: 0.25393277729299973 validation loss: 0.25239205404614556
epoch 8 time used: 12  seconds  train loss: 0.2502271887491921 validation loss: 0.24519529198314963
epoch 9 time used: 12  seconds  train loss: 0.2453571594680681 validation loss: 0.2431861027709702
epoch 10 time used: 12  seconds  train loss: 0.24136223807508253 validation loss: 0.24250000512096723
epoch 11 time used: 12  seconds  train loss: 0.24041678185353343 validation loss: 0.2391250297146665
epoch 12 time used: 12  seconds  train loss: 0.23590210098609266 validation loss: 0.2348952942569801
epoch 13 time used: 12  seconds  train loss: 0.23348409451002558 validation loss: 0.23322990692246662
epoch 14 time used: 12  seconds  train loss: 0.23259626314369522 validation loss: 0.23099532133500641
epoch 15 time used: 12  seconds  train loss: 0.22996123858527404 validation loss: 0.2299291119361971
epoch 16 time used: 12  seconds  train loss: 0.2294659996687647 validation loss: 0.22926178201395514
epoch 17 time used: 12  seconds  train loss: 0.22749169774287914 validation loss: 0.22734959494095153
epoch 18 time used: 12  seconds  train loss: 0.2259498067834224 validation loss: 0.22847717897557424
epoch 19 time used: 12  seconds  train loss: 0.22381385437412996 validation loss: 0.22525979552993894
epoch 20 time used: 12  seconds  train loss: 0.223001059226116 validation loss: 0.22501979742775083
epoch 21 time used: 12  seconds  train loss: 0.22198944480286228 validation loss: 0.22676121798400803
epoch 22 time used: 12  seconds  train loss: 0.2203418580851028 validation loss: 0.2211683648471076
epoch 23 time used: 12  seconds  train loss: 0.21896214551439028 validation loss: 0.22094768817874955
epoch 24 time used: 12  seconds  train loss: 0.21948730668650024 validation loss: 0.22105662545951107
epoch 25 time used: 12  seconds  train loss: 0.21748934866921849 validation loss: 0.22054672042302112
epoch 26 time used: 12  seconds  train loss: 0.2172683880126628 validation loss: 0.22390321694437734
epoch 27 time used: 12  seconds  train loss: 0.21504181679818 validation loss: 0.21648008405686242
epoch 28 time used: 12  seconds  train loss: 0.21432199676280927 validation loss: 0.22022445651203718
epoch 29 time used: 12  seconds  train loss: 0.21325762038865229 validation loss: 0.21863553003624242
epoch 30 time used: 12  seconds  train loss: 0.2128008601134555 validation loss: 0.22029557567423436
epoch 31 time used: 12  seconds  train loss: 0.21096324324024823 validation loss: 0.21494295346485298
epoch 32 time used: 12  seconds  train loss: 0.21069813071029522 validation loss: 0.2135449471945635
epoch 33 time used: 12  seconds  train loss: 0.21040765636998043 validation loss: 0.21843998054232655
epoch 34 time used: 12  seconds  train loss: 0.20942637707672487 validation loss: 0.2127913873126285
epoch 35 time used: 12  seconds  train loss: 0.20930649272618948 validation loss: 0.21327297909730378
epoch 36 time used: 12  seconds  train loss: 0.20789762525380454 validation loss: 0.21189835418549116
epoch 37 time used: 12  seconds  train loss: 0.208409919810093 validation loss: 0.21099896155217002
epoch 38 time used: 12  seconds  train loss: 0.2068928882144428 validation loss: 0.21795745042651568
epoch 39 time used: 12  seconds  train loss: 0.20690790724396743 validation loss: 0.20942771461985143
epoch 40 time used: 12  seconds  train loss: 0.20559014941626122 validation loss: 0.21271402861857103
epoch 41 time used: 12  seconds  train loss: 0.20483007632076916 validation loss: 0.2084313642703256
epoch 42 time used: 12  seconds  train loss: 0.20387833761515894 validation loss: 0.2099194139395179
epoch 43 time used: 12  seconds  train loss: 0.2041086625121959 validation loss: 0.20727796356166625
epoch 44 time used: 12  seconds  train loss: 0.20325937202029637 validation loss: 0.2066152000335442
epoch 45 time used: 12  seconds  train loss: 0.20194570464150385 validation loss: 0.21064717702979846
epoch 46 time used: 12  seconds  train loss: 0.2024724202471678 validation loss: 0.20593569773268985
epoch 47 time used: 12  seconds  train loss: 0.20100505897829343 validation loss: 0.20792173235095437
epoch 48 time used: 12  seconds  train loss: 0.20095829244424904 validation loss: 0.21143226414765892
epoch 49 time used: 12  seconds  train loss: 0.20054955789251516 validation loss: 0.20664057479847245
epoch 50 time used: 12  seconds  train loss: 0.1993371880487856 validation loss: 0.2057256725554594
epoch 51 time used: 12  seconds  train loss: 0.19917247257094295 validation loss: 0.2046045135904297
epoch 52 time used: 12  seconds  train loss: 0.19956894277710072 validation loss: 0.20335025909418933
epoch 53 time used: 12  seconds  train loss: 0.19806116361706663 validation loss: 0.20419188692987272
epoch 54 time used: 12  seconds  train loss: 0.19759264163233226 validation loss: 0.20404849330221525
epoch 55 time used: 12  seconds  train loss: 0.1973497801896684 validation loss: 0.20598699200071746
epoch 56 time used: 12  seconds  train loss: 0.19674094150071816 validation loss: 0.20201498112777813
epoch 57 time used: 12  seconds  train loss: 0.19695873508964098 validation loss: 0.20594844334273765
epoch 58 time used: 12  seconds  train loss: 0.19562251805131972 validation loss: 0.20064654102239757
epoch 59 time used: 12  seconds  train loss: 0.19497939085276306 validation loss: 0.20106672649885407
epoch 60 time used: 12  seconds  train loss: 0.19520264838703455 validation loss: 0.20271627172292198
epoch 61 time used: 12  seconds  train loss: 0.19437045853962756 validation loss: 0.20337141777404158
epoch 62 time used: 12  seconds  train loss: 0.19430845564842847 validation loss: 0.2014251949698056
epoch 63 time used: 12  seconds  train loss: 0.19391241484544236 validation loss: 0.2000865081736379
epoch 64 time used: 12  seconds  train loss: 0.19390272206520856 validation loss: 0.20116679971379955
epoch 65 time used: 12  seconds  train loss: 0.19311709322562465 validation loss: 0.20197638508869592
epoch 66 time used: 12  seconds  train loss: 0.19212123048608684 validation loss: 0.19957106388336035
epoch 67 time used: 12  seconds  train loss: 0.19205465771435215 validation loss: 0.19905810527337733
epoch 68 time used: 12  seconds  train loss: 0.19173803049032487 validation loss: 0.20010816551961697
epoch 69 time used: 12  seconds  train loss: 0.19157917816999645 validation loss: 0.19869159501209574
epoch 70 time used: 12  seconds  train loss: 0.19077535115005062 validation loss: 0.19964931878068415
epoch 71 time used: 12  seconds  train loss: 0.19077576098785673 validation loss: 0.19733361283575407
epoch 72 time used: 12  seconds  train loss: 0.18980992357797719 validation loss: 0.19771202542716548
epoch 73 time used: 12  seconds  train loss: 0.19017909286482387 validation loss: 0.19837722275778014
epoch 74 time used: 12  seconds  train loss: 0.1897733640818476 validation loss: 0.19730234206470842
epoch 75 time used: 12  seconds  train loss: 0.1897514253699278 validation loss: 0.19626846698713657
epoch 76 time used: 12  seconds  train loss: 0.18817661163334276 validation loss: 0.19715353288075207
epoch 77 time used: 12  seconds  train loss: 0.18849678523656324 validation loss: 0.19689632056273532
epoch 78 time used: 12  seconds  train loss: 0.18829497164415931 validation loss: 0.19621076639284765
epoch 79 time used: 12  seconds  train loss: 0.18746819154501818 validation loss: 0.1959265118079123
epoch 80 time used: 12  seconds  train loss: 0.18744995704216486 validation loss: 0.19817461001145384
epoch 81 time used: 12  seconds  train loss: 0.18724693606702053 validation loss: 0.1961263520202158
epoch 82 time used: 12  seconds  train loss: 0.18751132989166847 validation loss: 0.19685435319756076
epoch 83 time used: 12  seconds  train loss: 0.18660749912864422 validation loss: 0.1955284749057316
epoch 84 time used: 12  seconds  train loss: 0.18626677498760696 validation loss: 0.19377159610756178
epoch 85 time used: 12  seconds  train loss: 0.18613073957599954 validation loss: 0.19461157093439793
epoch 86 time used: 12  seconds  train loss: 0.18538539255427194 validation loss: 0.19496393203735352
epoch 87 time used: 12  seconds  train loss: 0.18568653470730603 validation loss: 0.1940463012327688
epoch 88 time used: 12  seconds  train loss: 0.18486960843462955 validation loss: 0.19343193296153954
epoch 89 time used: 12  seconds  train loss: 0.18546798972963782 validation loss: 0.194517858730203
epoch 90 time used: 12  seconds  train loss: 0.18432054564934972 validation loss: 0.1930384042938981
epoch 91 time used: 12  seconds  train loss: 0.18460921614264136 validation loss: 0.19269754525531174
epoch 92 time used: 12  seconds  train loss: 0.18374299787332307 validation loss: 0.19292819012047832
epoch 93 time used: 12  seconds  train loss: 0.182826291472157 validation loss: 0.1943387204214837
epoch 94 time used: 12  seconds  train loss: 0.1838875833059469 validation loss: 0.1926268654776109
epoch 95 time used: 12  seconds  train loss: 0.1833148348212903 validation loss: 0.1926891045507811
epoch 96 time used: 12  seconds  train loss: 0.18277980411017722 validation loss: 0.1956696519835364
epoch 97 time used: 12  seconds  train loss: 0.18280410355568555 validation loss: 0.19236637158898443
epoch 98 time used: 12  seconds  train loss: 0.1822676772854792 validation loss: 0.19268979695750452
epoch 99 time used: 12  seconds  train loss: 0.18304318629805258 validation loss: 0.19248761068360165
epoch 100 time used: 12  seconds  train loss: 0.18199734701214762 validation loss: 0.191839166610362
epoch 101 time used: 12  seconds  train loss: 0.18220256290841577 validation loss: 0.19308440410200012
epoch 102 time used: 12  seconds  train loss: 0.18135486552409796 validation loss: 0.19153164090834138
epoch 103 time used: 12  seconds  train loss: 0.18139441423105968 validation loss: 0.19121010367760166
epoch 104 time used: 12  seconds  train loss: 0.18055823903481036 validation loss: 0.19203858579048347
epoch 105 time used: 12  seconds  train loss: 0.18126338114460944 validation loss: 0.19597949771900144
epoch 106 time used: 12  seconds  train loss: 0.1807165605492494 validation loss: 0.18968890927821244
epoch 107 time used: 12  seconds  train loss: 0.18081010477741882 validation loss: 0.190927835520308
epoch 108 time used: 12  seconds  train loss: 0.17981127855790957 validation loss: 0.1911788544720129
epoch 109 time used: 12  seconds  train loss: 0.17992755828014134 validation loss: 0.19192404973629332
epoch 110 time used: 12  seconds  train loss: 0.17964414069638565 validation loss: 0.1900795692045622
epoch 111 time used: 12  seconds  train loss: 0.17900116468121105 validation loss: 0.19130813104726896
epoch 112 time used: 12  seconds  train loss: 0.18008613131665857 validation loss: 0.19634635306159495
epoch 113 time used: 12  seconds  train loss: 0.17894449572066434 validation loss: 0.19059115194349513
epoch 114 time used: 12  seconds  train loss: 0.17879292639995734 validation loss: 0.18981575394656
epoch 115 time used: 12  seconds  train loss: 0.17915626062626244 validation loss: 0.1898615005199255
epoch 116 time used: 12  seconds  train loss: 0.17840609230395052 validation loss: 0.18853591133442457
epoch 117 time used: 12  seconds  train loss: 0.17791867777486559 validation loss: 0.18917454541987577
epoch 118 time used: 12  seconds  train loss: 0.17867278021265018 validation loss: 0.18838538250716427
epoch 119 time used: 12  seconds  train loss: 0.17795906306032175 validation loss: 0.1886718644459317
epoch 120 time used: 12  seconds  train loss: 0.17820459079540316 validation loss: 0.18804222665816392
epoch 121 time used: 12  seconds  train loss: 0.177046696356348 validation loss: 0.1889314037932033
epoch 122 time used: 12  seconds  train loss: 0.17718591530120137 validation loss: 0.18942742785826724
epoch 123 time used: 12  seconds  train loss: 0.17794061038445136 validation loss: 0.18882702870737533
epoch 124 time used: 12  seconds  train loss: 0.17729136016903696 validation loss: 0.18927245517832444
epoch 125 time used: 12  seconds  train loss: 0.17666510360167864 validation loss: 0.18913994377603274
epoch 126 time used: 12  seconds  train loss: 0.17667298220076155 validation loss: 0.18902751076615884
epoch 127 time used: 12  seconds  train loss: 0.1770977446494213 validation loss: 0.1905073738155947
epoch 128 time used: 12  seconds  train loss: 0.176858777613332 validation loss: 0.1872318964717188
epoch 129 time used: 12  seconds  train loss: 0.1753841235840169 validation loss: 0.19043628380119088
epoch 130 time used: 12  seconds  train loss: 0.1757619258029709 validation loss: 0.18835488727653088
epoch 131 time used: 12  seconds  train loss: 0.17553359593675003 validation loss: 0.18689937484958005
epoch 132 time used: 12  seconds  train loss: 0.17523790188534547 validation loss: 0.1863859686437363
epoch 133 time used: 12  seconds  train loss: 0.17563306968045772 validation loss: 0.19021834754393024
epoch 134 time used: 12  seconds  train loss: 0.17573406926031646 validation loss: 0.18872904657671538
epoch 135 time used: 12  seconds  train loss: 0.17553894921413338 validation loss: 0.18888359335376
epoch 136 time used: 12  seconds  train loss: 0.17527002654423104 validation loss: 0.1874881312633608
epoch 137 time used: 12  seconds  train loss: 0.17450322518334702 validation loss: 0.1859303852336038
epoch 138 time used: 12  seconds  train loss: 0.17458456547224527 validation loss: 0.18606862832972204
epoch 139 time used: 12  seconds  train loss: 0.1751330409467434 validation loss: 0.19108569453732327
epoch 140 time used: 12  seconds  train loss: 0.17507192795172474 validation loss: 0.18604165738946835
epoch 141 time used: 12  seconds  train loss: 0.17415240268521484 validation loss: 0.18705453681592185
epoch 142 time used: 12  seconds  train loss: 0.17443271255333803 validation loss: 0.18615575721280206
epoch 143 time used: 12  seconds  train loss: 0.1736495471570093 validation loss: 0.18626791613651425
epoch 144 time used: 12  seconds  train loss: 0.17427437440323681 validation loss: 0.18493118914480694
epoch 145 time used: 12  seconds  train loss: 0.1735384988306709 validation loss: 0.18723643749221283
epoch 146 time used: 12  seconds  train loss: 0.17468220894329703 validation loss: 0.1898709947952052
epoch 147 time used: 12  seconds  train loss: 0.17325955433549342 validation loss: 0.18488169397310877
epoch 148 time used: 12  seconds  train loss: 0.17304618409821138 validation loss: 0.18756849962646324
epoch 149 time used: 12  seconds  train loss: 0.17326586968276103 validation loss: 0.1860194089952633
epoch 150 time used: 12  seconds  train loss: 0.17297802605087143 validation loss: 0.18984734585335508
epoch 151 time used: 12  seconds  train loss: 0.1734392975688097 validation loss: 0.19075083861810713
epoch 152 time used: 12  seconds  train loss: 0.17348846990431718 validation loss: 0.18607683057317173
epoch 153 time used: 12  seconds  train loss: 0.17235336675486893 validation loss: 0.1855368621762113
epoch 154 time used: 12  seconds  train loss: 0.17252036326184972 validation loss: 0.18617205473095502
epoch 155 time used: 12  seconds  train loss: 0.17241294890943396 validation loss: 0.18598089986403737
epoch 156 time used: 12  seconds  train loss: 0.1730081609650392 validation loss: 0.18588578872726907
epoch 157 time used: 12  seconds  train loss: 0.17199471702706282 validation loss: 0.18380866337862956
epoch 158 time used: 12  seconds  train loss: 0.17145654064049579 validation loss: 0.18615029719103016
epoch 159 time used: 12  seconds  train loss: 0.17229481262009425 validation loss: 0.18415841120212878
epoch 160 time used: 12  seconds  train loss: 0.17185852146805558 validation loss: 0.18645965054214714
epoch 161 time used: 12  seconds  train loss: 0.17165498174593352 validation loss: 0.18551223785858187
epoch 162 time used: 12  seconds  train loss: 0.1723970010133298 validation loss: 0.18416603406837037
epoch 163 time used: 12  seconds  train loss: 0.17159276998097475 validation loss: 0.18729275343456203
epoch 164 time used: 12  seconds  train loss: 0.17143422565360703 validation loss: 0.18488883715456578
epoch 165 time used: 12  seconds  train loss: 0.17136558436068644 validation loss: 0.183574529712158
epoch 166 time used: 12  seconds  train loss: 0.17097293378321868 validation loss: 0.1857067785277342
epoch 167 time used: 12  seconds  train loss: 0.17174432457056968 validation loss: 0.18471182646475312
epoch 168 time used: 12  seconds  train loss: 0.1713616505221509 validation loss: 0.1837401929934638
epoch 169 time used: 12  seconds  train loss: 0.17093702240743502 validation loss: 0.18335901769446564
epoch 170 time used: 12  seconds  train loss: 0.17157452728661257 validation loss: 0.1845056339800868
epoch 171 time used: 12  seconds  train loss: 0.1707636117012057 validation loss: 0.18442590398681008
epoch 172 time used: 12  seconds  train loss: 0.17061748745525393 validation loss: 0.18413981876064558
epoch 173 time used: 12  seconds  train loss: 0.17007452618290633 validation loss: 0.18355070513551466
epoch 174 time used: 12  seconds  train loss: 0.1702058071961106 validation loss: 0.18396636484965417
epoch 175 time used: 12  seconds  train loss: 0.17013829181782772 validation loss: 0.18315771732987232
epoch 176 time used: 12  seconds  train loss: 0.17099807922794255 validation loss: 0.18511135133245776
epoch 177 time used: 12  seconds  train loss: 0.17048247470931896 validation loss: 0.18288007517984373
epoch 178 time used: 12  seconds  train loss: 0.170309542176348 validation loss: 0.18248321586891508
epoch 179 time used: 12  seconds  train loss: 0.17005880445698632 validation loss: 0.1842530691922901
epoch 180 time used: 12  seconds  train loss: 0.16975818723100072 validation loss: 0.18389400175076107
epoch 181 time used: 12  seconds  train loss: 0.16934185773668672 validation loss: 0.18348051638210153
epoch 182 time used: 12  seconds  train loss: 0.16968338907658956 validation loss: 0.1823873518452397
epoch 183 time used: 12  seconds  train loss: 0.16938553090238556 validation loss: 0.18345786851267099
epoch 184 time used: 12  seconds  train loss: 0.16990786420626558 validation loss: 0.18253378434923806
epoch 185 time used: 12  seconds  train loss: 0.16927881445583864 validation loss: 0.18357869090179818
epoch 186 time used: 12  seconds  train loss: 0.16924519359793383 validation loss: 0.18399815289415228
epoch 187 time used: 12  seconds  train loss: 0.16984642684498555 validation loss: 0.18378621450302876
epoch 188 time used: 12  seconds  train loss: 0.16852043736707825 validation loss: 0.18446406126192347
epoch 189 time used: 12  seconds  train loss: 0.16939109396207672 validation loss: 0.18349479213654485
epoch 190 time used: 12  seconds  train loss: 0.1688832218294467 validation loss: 0.1833367376873579
epoch 191 time used: 12  seconds  train loss: 0.1688549465141197 validation loss: 0.18151213381709336
epoch 192 time used: 12  seconds  train loss: 0.16905145478299125 validation loss: 0.18130737135938013
epoch 193 time used: 12  seconds  train loss: 0.16875852548244297 validation loss: 0.1814778115381463
epoch 194 time used: 12  seconds  train loss: 0.16853274254387662 validation loss: 0.18451757286183845
epoch 195 time used: 12  seconds  train loss: 0.16824305622088703 validation loss: 0.1816327236444013
epoch 196 time used: 12  seconds  train loss: 0.1682820855784113 validation loss: 0.18209439017095363
epoch 197 time used: 12  seconds  train loss: 0.16775347540209104 validation loss: 0.1821126559429419
epoch 198 time used: 12  seconds  train loss: 0.16818645058663148 validation loss: 0.18188037416864244
epoch 199 time used: 11  seconds  train loss: 0.1678273106072211 validation loss: 0.1822202270515837
YS.shape, YS_pred.shape before, (14021, 3, 69, 1) (14021, 3, 69, 1)
YS.shape, YS_pred.shape after, (14021, 3, 69) (14021, 3, 69)
YS_pred.shape before (14021, 3, 69)
YS_pred.shape after (14021, 3, 69)
YS.shape, YS_pred.shape, (14021, 3, 69) (14021, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 1.6444425694e-01, 0.1644442569
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 338.1408266181, 18.3886058911, 10.6126495918, 15.9923778776
Model Training Ended ... Sun Dec 26 22:25:11 2021
pred_METR-LA_GraphWaveNet_2112262144 testing started Sun Dec 26 22:25:11 2021
TEST XS.shape, YS.shape (3507, 2, 69, 12) (3507, 3, 69, 1)
Model Testing Started ... Sun Dec 26 22:25:11 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (3507, 3, 69, 1) (3507, 3, 69, 1)
YS.shape, YS_pred.shape after, (3507, 3, 69) (3507, 3, 69)
YS.shape, YS_pred.shape, (3507, 3, 69) (3507, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 1.7626645540e-01, 0.1762664554
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 378.1576498571, 19.4462759894, 11.1759339156, 17.2518330745
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 324.2758270564, 18.0076602327, 10.7018237867, 16.7332399014
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 378.0503076179, 19.4435158245, 11.1187988154, 17.1323216068
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 432.1461250635, 20.7881246163, 11.7071736744, 17.8899320191
Model Testing Ended ... Sun Dec 26 22:25:12 2021
