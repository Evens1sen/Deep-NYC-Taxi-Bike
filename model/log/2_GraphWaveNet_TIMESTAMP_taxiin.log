nohup: ignoring input
data.shape (17544, 69)
pred_METR-LA_GraphWaveNet_220108235733 training started Sat Jan  8 23:57:33 2022
TRAIN XS.shape YS,shape (14021, 2, 69, 12) (14021, 3, 69, 1)
Model Training Started ... Sat Jan  8 23:57:33 2022
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          96
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-5                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-7                  [-1, 32, 69, 12]          7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-10                  [-1, 32, 69, 10]          --
|    |    └─nconv: 3-11                  [-1, 32, 69, 10]          --
|    |    └─nconv: 3-12                  [-1, 32, 69, 10]          --
|    |    └─nconv: 3-13                  [-1, 32, 69, 10]          --
|    |    └─linear: 3-14                 [-1, 32, 69, 10]          7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-15                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-20                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-21                 [-1, 32, 69, 9]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-25                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-28                 [-1, 32, 69, 7]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-30                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 6]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-40                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-41                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-42                 [-1, 32, 69, 4]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-43                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-44                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-45                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-46                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-47                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-48                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-49                 [-1, 32, 69, 3]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-50                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-51                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-52                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-53                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-54                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-55                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-56                 [-1, 32, 69, 1]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 292,195
Trainable params: 292,195
Non-trainable params: 0
Total mult-adds (M): 79.13
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 11.00
Params size (MB): 1.11
Estimated Total Size (MB): 12.12
==========================================================================================
XS_torch.shape:   torch.Size([14021, 2, 69, 12])
YS_torch.shape:   torch.Size([14021, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 70  seconds  train loss: 0.4185912925683212 validation loss: 0.35046818702817983
epoch 1 time used: 73  seconds  train loss: 0.36102417516599544 validation loss: 0.3220758340186006
epoch 2 time used: 73  seconds  train loss: 0.3350194714475152 validation loss: 0.30839209215204444
epoch 3 time used: 73  seconds  train loss: 0.3171295316183571 validation loss: 0.299733144245485
epoch 4 time used: 73  seconds  train loss: 0.30517504975700127 validation loss: 0.29589991738166527
epoch 5 time used: 73  seconds  train loss: 0.2981332001019115 validation loss: 0.2854227792754285
epoch 6 time used: 73  seconds  train loss: 0.28986021056212546 validation loss: 0.2800969365353048
epoch 7 time used: 73  seconds  train loss: 0.28363568170823916 validation loss: 0.2750592387817413
epoch 8 time used: 73  seconds  train loss: 0.2797600322606162 validation loss: 0.27287755652420603
epoch 9 time used: 73  seconds  train loss: 0.2760276368436263 validation loss: 0.2690425006342288
epoch 10 time used: 73  seconds  train loss: 0.2713229377533272 validation loss: 0.2636593089434193
epoch 11 time used: 73  seconds  train loss: 0.2696492799551976 validation loss: 0.26431122979843064
epoch 12 time used: 73  seconds  train loss: 0.2673431927387435 validation loss: 0.2613274585976304
epoch 13 time used: 73  seconds  train loss: 0.2640670571569748 validation loss: 0.255728874455434
epoch 14 time used: 73  seconds  train loss: 0.26168445496050746 validation loss: 0.25574342348850326
epoch 15 time used: 73  seconds  train loss: 0.2599704730265841 validation loss: 0.25269234647971184
epoch 16 time used: 73  seconds  train loss: 0.2579180108809028 validation loss: 0.2579582844267419
epoch 17 time used: 73  seconds  train loss: 0.2566386669300883 validation loss: 0.25193139604684356
epoch 18 time used: 73  seconds  train loss: 0.2561927931361996 validation loss: 0.25158565774075453
epoch 19 time used: 73  seconds  train loss: 0.2534419577052549 validation loss: 0.24824367447437998
epoch 20 time used: 73  seconds  train loss: 0.2517288937061821 validation loss: 0.24594481973667112
epoch 21 time used: 73  seconds  train loss: 0.25193737949635486 validation loss: 0.2472395923432798
epoch 22 time used: 73  seconds  train loss: 0.24893420002322109 validation loss: 0.2481676601744759
epoch 23 time used: 72  seconds  train loss: 0.2479194325152305 validation loss: 0.24219268949726822
epoch 24 time used: 73  seconds  train loss: 0.24680000093692983 validation loss: 0.2449312283016244
epoch 25 time used: 73  seconds  train loss: 0.24712516329052941 validation loss: 0.24291137284166256
epoch 26 time used: 73  seconds  train loss: 0.24454194817474623 validation loss: 0.23978072097147796
epoch 27 time used: 73  seconds  train loss: 0.2439252171224517 validation loss: 0.24421469217800645
epoch 28 time used: 73  seconds  train loss: 0.24368719324678484 validation loss: 0.2426081040605299
epoch 29 time used: 73  seconds  train loss: 0.24256017611747382 validation loss: 0.23785020501118556
epoch 30 time used: 73  seconds  train loss: 0.24192192994075137 validation loss: 0.24084990228915718
epoch 31 time used: 73  seconds  train loss: 0.2411922258636172 validation loss: 0.2366852832738155
epoch 32 time used: 73  seconds  train loss: 0.24087531487134056 validation loss: 0.23688822353967448
epoch 33 time used: 73  seconds  train loss: 0.2400915673434404 validation loss: 0.24307739930158334
epoch 34 time used: 73  seconds  train loss: 0.2403996927578052 validation loss: 0.23894636984967668
epoch 35 time used: 73  seconds  train loss: 0.23894545181317636 validation loss: 0.23573716039223733
epoch 36 time used: 72  seconds  train loss: 0.23812093721525965 validation loss: 0.2406341189394253
epoch 37 time used: 73  seconds  train loss: 0.2374466620324915 validation loss: 0.23360753372201087
epoch 38 time used: 72  seconds  train loss: 0.23701861153839854 validation loss: 0.23823672578937316
epoch 39 time used: 73  seconds  train loss: 0.23618060508320843 validation loss: 0.23535421887636865
epoch 40 time used: 73  seconds  train loss: 0.235954326077358 validation loss: 0.2358911175831209
epoch 41 time used: 73  seconds  train loss: 0.23447278241089745 validation loss: 0.23244371483207632
epoch 42 time used: 73  seconds  train loss: 0.23432782575133418 validation loss: 0.23271832722666871
epoch 43 time used: 73  seconds  train loss: 0.23443617452364773 validation loss: 0.23126266996179115
epoch 44 time used: 73  seconds  train loss: 0.23298349699602477 validation loss: 0.23658329188075666
epoch 45 time used: 73  seconds  train loss: 0.2336376347825937 validation loss: 0.2304277387402497
epoch 46 time used: 73  seconds  train loss: 0.232577479586253 validation loss: 0.23260906870815323
epoch 47 time used: 73  seconds  train loss: 0.2321709579322639 validation loss: 0.2339819776913267
epoch 48 time used: 73  seconds  train loss: 0.2314932053859513 validation loss: 0.231206640575657
epoch 49 time used: 73  seconds  train loss: 0.23211026028950127 validation loss: 0.22991920173746208
epoch 50 time used: 73  seconds  train loss: 0.23081678671948794 validation loss: 0.23134247191076066
epoch 51 time used: 72  seconds  train loss: 0.23061962041397766 validation loss: 0.2310884215120445
epoch 52 time used: 73  seconds  train loss: 0.23000287530105046 validation loss: 0.2291288039664575
epoch 53 time used: 72  seconds  train loss: 0.2298825253365986 validation loss: 0.23202577310667946
epoch 54 time used: 73  seconds  train loss: 0.22982809398922113 validation loss: 0.22956145894371027
epoch 55 time used: 73  seconds  train loss: 0.22898079924234396 validation loss: 0.22740581161589604
epoch 56 time used: 73  seconds  train loss: 0.2289099250150341 validation loss: 0.22658775721321225
epoch 57 time used: 73  seconds  train loss: 0.22778757504892924 validation loss: 0.2284315164879398
epoch 58 time used: 73  seconds  train loss: 0.22757106469922864 validation loss: 0.22835102941707006
epoch 59 time used: 73  seconds  train loss: 0.22760847069986254 validation loss: 0.22508839661913196
epoch 60 time used: 73  seconds  train loss: 0.2273119677539598 validation loss: 0.22570180311518537
epoch 61 time used: 73  seconds  train loss: 0.2262677964166822 validation loss: 0.22451357597870888
epoch 62 time used: 73  seconds  train loss: 0.22626457628400776 validation loss: 0.22429432954981338
epoch 63 time used: 73  seconds  train loss: 0.22605820239697988 validation loss: 0.22770451562648084
epoch 64 time used: 73  seconds  train loss: 0.22568055329996792 validation loss: 0.22413342656473126
epoch 65 time used: 73  seconds  train loss: 0.22582209646157655 validation loss: 0.22401336701645283
epoch 66 time used: 73  seconds  train loss: 0.2251925423940541 validation loss: 0.2284449063245732
epoch 67 time used: 73  seconds  train loss: 0.22443445830963937 validation loss: 0.2241529861621291
epoch 68 time used: 73  seconds  train loss: 0.22388544592205928 validation loss: 0.2243506462996984
epoch 69 time used: 73  seconds  train loss: 0.2247632904446471 validation loss: 0.22355744003807554
epoch 70 time used: 73  seconds  train loss: 0.2235383850318584 validation loss: 0.22735388872797532
epoch 71 time used: 73  seconds  train loss: 0.22305706659356817 validation loss: 0.22667363103260263
epoch 72 time used: 73  seconds  train loss: 0.2231554403526992 validation loss: 0.22460061948400054
epoch 73 time used: 73  seconds  train loss: 0.22272357017161368 validation loss: 0.22246667241206933
epoch 74 time used: 73  seconds  train loss: 0.22282441586188007 validation loss: 0.22454114814214005
epoch 75 time used: 73  seconds  train loss: 0.2219478153894808 validation loss: 0.22289972108429115
epoch 76 time used: 73  seconds  train loss: 0.22160667808739185 validation loss: 0.2218647326868191
epoch 77 time used: 73  seconds  train loss: 0.22129656057677285 validation loss: 0.22489451093804272
epoch 78 time used: 73  seconds  train loss: 0.22153068082434446 validation loss: 0.22163799660109276
epoch 79 time used: 73  seconds  train loss: 0.22081656359502924 validation loss: 0.22180017548428899
epoch 80 time used: 73  seconds  train loss: 0.2207247125021907 validation loss: 0.22148382171554967
epoch 81 time used: 73  seconds  train loss: 0.22116740375397684 validation loss: 0.22040391590550362
epoch 82 time used: 73  seconds  train loss: 0.22013090112172784 validation loss: 0.2201506451868834
epoch 83 time used: 73  seconds  train loss: 0.22035304013606893 validation loss: 0.2197553967654331
epoch 84 time used: 73  seconds  train loss: 0.2197280425200604 validation loss: 0.21955589184200702
epoch 85 time used: 73  seconds  train loss: 0.21990805261388524 validation loss: 0.2191125971806505
epoch 86 time used: 73  seconds  train loss: 0.21846939116609496 validation loss: 0.2183123191492393
epoch 87 time used: 73  seconds  train loss: 0.2188797998513855 validation loss: 0.21864454475424322
epoch 88 time used: 73  seconds  train loss: 0.2187362470007269 validation loss: 0.218987445294415
epoch 89 time used: 73  seconds  train loss: 0.21818021366407322 validation loss: 0.21879412476940285
epoch 90 time used: 73  seconds  train loss: 0.21879095866192735 validation loss: 0.22175455340744765
epoch 91 time used: 72  seconds  train loss: 0.21778451555378475 validation loss: 0.22220982054404648
epoch 92 time used: 72  seconds  train loss: 0.21762278355368972 validation loss: 0.2188623935001208
epoch 93 time used: 73  seconds  train loss: 0.21726881988397592 validation loss: 0.221686177520975
epoch 94 time used: 73  seconds  train loss: 0.21727354257064804 validation loss: 0.21904129172418707
epoch 95 time used: 73  seconds  train loss: 0.21636793520246922 validation loss: 0.21871428776487783
epoch 96 time used: 73  seconds  train loss: 0.2166433049688364 validation loss: 0.21700093224092137
epoch 97 time used: 73  seconds  train loss: 0.21622146758362334 validation loss: 0.2180612658220091
epoch 98 time used: 73  seconds  train loss: 0.2165948139812723 validation loss: 0.21953302751897202
epoch 99 time used: 73  seconds  train loss: 0.21624205597923213 validation loss: 0.21900279203688017
epoch 100 time used: 73  seconds  train loss: 0.21570176069321367 validation loss: 0.21757511304095345
epoch 101 time used: 73  seconds  train loss: 0.21580106038922084 validation loss: 0.2167708231375276
epoch 102 time used: 73  seconds  train loss: 0.21568694257915 validation loss: 0.2171608511118364
epoch 103 time used: 73  seconds  train loss: 0.21461661543331514 validation loss: 0.2172420907721
epoch 104 time used: 73  seconds  train loss: 0.2146499942287312 validation loss: 0.2173070325146929
epoch 105 time used: 73  seconds  train loss: 0.2144516827007206 validation loss: 0.2172163210966488
epoch 106 time used: 73  seconds  train loss: 0.21483977761861747 validation loss: 0.2169341250650555
epoch 107 time used: 73  seconds  train loss: 0.2142003903005735 validation loss: 0.21555387162849418
epoch 108 time used: 73  seconds  train loss: 0.21365516802601522 validation loss: 0.21744170256226797
epoch 109 time used: 73  seconds  train loss: 0.21398208020446274 validation loss: 0.2150231042693019
epoch 110 time used: 73  seconds  train loss: 0.21306204701095752 validation loss: 0.21365928717055324
epoch 111 time used: 73  seconds  train loss: 0.21320215795088326 validation loss: 0.2171513485656897
epoch 112 time used: 73  seconds  train loss: 0.21295317275286266 validation loss: 0.215706528567683
epoch 113 time used: 73  seconds  train loss: 0.2132781410124001 validation loss: 0.2146403574545725
epoch 114 time used: 73  seconds  train loss: 0.21300449795877657 validation loss: 0.21523241266072715
epoch 115 time used: 73  seconds  train loss: 0.21282473005862124 validation loss: 0.213140326546249
epoch 116 time used: 73  seconds  train loss: 0.21184695392293187 validation loss: 0.21498595544493546
epoch 117 time used: 73  seconds  train loss: 0.21201311905492118 validation loss: 0.21467085436828057
epoch 118 time used: 73  seconds  train loss: 0.21217002216538272 validation loss: 0.2146612396256555
epoch 119 time used: 73  seconds  train loss: 0.21144263260248705 validation loss: 0.21351134053686993
epoch 120 time used: 73  seconds  train loss: 0.21133569287659099 validation loss: 0.21508951640713916
epoch 121 time used: 73  seconds  train loss: 0.2115513682316832 validation loss: 0.21314729088827059
epoch 122 time used: 73  seconds  train loss: 0.21119824259802772 validation loss: 0.21344885905844377
epoch 123 time used: 73  seconds  train loss: 0.21031472604341603 validation loss: 0.21246561963967575
epoch 124 time used: 73  seconds  train loss: 0.21061006268558652 validation loss: 0.21273835283038417
epoch 125 time used: 73  seconds  train loss: 0.20964569190075547 validation loss: 0.21172612987955977
epoch 126 time used: 73  seconds  train loss: 0.21035026912682211 validation loss: 0.2113289501129119
epoch 127 time used: 73  seconds  train loss: 0.21003896540214856 validation loss: 0.21209917810394366
epoch 128 time used: 73  seconds  train loss: 0.20977002464873729 validation loss: 0.21338502154884784
epoch 129 time used: 73  seconds  train loss: 0.21036096580902294 validation loss: 0.21197544601870752
epoch 130 time used: 73  seconds  train loss: 0.2092953307167264 validation loss: 0.21077428160567863
epoch 131 time used: 73  seconds  train loss: 0.20927191347146135 validation loss: 0.21190286565017374
epoch 132 time used: 73  seconds  train loss: 0.2090610572549004 validation loss: 0.21264801039671258
epoch 133 time used: 73  seconds  train loss: 0.20897664566517343 validation loss: 0.21353973755140135
epoch 134 time used: 73  seconds  train loss: 0.20858589865638955 validation loss: 0.21125381487951372
epoch 135 time used: 73  seconds  train loss: 0.20851074928739075 validation loss: 0.21130154286529837
epoch 136 time used: 72  seconds  train loss: 0.20849429755032858 validation loss: 0.21409841974972998
epoch 137 time used: 72  seconds  train loss: 0.20788712353048708 validation loss: 0.2106305838090246
epoch 138 time used: 73  seconds  train loss: 0.20818225722632425 validation loss: 0.21334553720334973
epoch 139 time used: 73  seconds  train loss: 0.20746554142786697 validation loss: 0.21111310346087114
epoch 140 time used: 73  seconds  train loss: 0.2073137376677302 validation loss: 0.2118300434884111
epoch 141 time used: 73  seconds  train loss: 0.20787816527012626 validation loss: 0.21207991098752377
epoch 142 time used: 73  seconds  train loss: 0.20731100166489178 validation loss: 0.21296634624940086
epoch 143 time used: 73  seconds  train loss: 0.20684492286327494 validation loss: 0.20903645201675972
epoch 144 time used: 73  seconds  train loss: 0.20656918268620406 validation loss: 0.209405506670441
epoch 145 time used: 73  seconds  train loss: 0.20706227122474113 validation loss: 0.208763621955753
epoch 146 time used: 73  seconds  train loss: 0.206745643752928 validation loss: 0.21025365676052965
epoch 147 time used: 73  seconds  train loss: 0.20638220480065958 validation loss: 0.20959620980181426
epoch 148 time used: 73  seconds  train loss: 0.20653491469423818 validation loss: 0.21124828514614857
epoch 149 time used: 73  seconds  train loss: 0.20579536146456076 validation loss: 0.20914566564478332
epoch 150 time used: 73  seconds  train loss: 0.2056445781060139 validation loss: 0.20864794772655978
epoch 151 time used: 73  seconds  train loss: 0.2053363433306327 validation loss: 0.2092042695316531
epoch 152 time used: 73  seconds  train loss: 0.20554237306739906 validation loss: 0.21031724868572854
epoch 153 time used: 73  seconds  train loss: 0.20516943321346187 validation loss: 0.20873413103618285
epoch 154 time used: 73  seconds  train loss: 0.20491180265031422 validation loss: 0.2083429590386115
epoch 155 time used: 73  seconds  train loss: 0.20454769824726557 validation loss: 0.20836024851677964
epoch 156 time used: 73  seconds  train loss: 0.20534495748931747 validation loss: 0.2079044440713394
epoch 157 time used: 72  seconds  train loss: 0.2041984584108408 validation loss: 0.20712191844013714
epoch 158 time used: 73  seconds  train loss: 0.2045986368878097 validation loss: 0.20835380806150397
epoch 159 time used: 73  seconds  train loss: 0.20493130868815193 validation loss: 0.20961337263286284
epoch 160 time used: 73  seconds  train loss: 0.2038755178752768 validation loss: 0.20799408834353217
epoch 161 time used: 73  seconds  train loss: 0.20395556551394883 validation loss: 0.20922545629675157
epoch 162 time used: 73  seconds  train loss: 0.2043533632012505 validation loss: 0.20772995777253891
epoch 163 time used: 74  seconds  train loss: 0.203754386229044 validation loss: 0.20800128509436616
epoch 164 time used: 74  seconds  train loss: 0.20347797038852877 validation loss: 0.2072670246387847
epoch 165 time used: 74  seconds  train loss: 0.20317134630380798 validation loss: 0.20857814617382753
epoch 166 time used: 74  seconds  train loss: 0.20312653201136327 validation loss: 0.20674902683520277
epoch 167 time used: 74  seconds  train loss: 0.20306023714847116 validation loss: 0.20808139547102122
epoch 168 time used: 74  seconds  train loss: 0.2029502945446525 validation loss: 0.20733156067537567
epoch 169 time used: 74  seconds  train loss: 0.2028449558603441 validation loss: 0.20739149093559928
epoch 170 time used: 74  seconds  train loss: 0.20299497957061702 validation loss: 0.20740092598875115
epoch 171 time used: 73  seconds  train loss: 0.20276716588120294 validation loss: 0.20554044684613015
epoch 172 time used: 72  seconds  train loss: 0.20178737183094492 validation loss: 0.20590228597164426
epoch 173 time used: 73  seconds  train loss: 0.20268941700536264 validation loss: 0.2053571820888122
epoch 174 time used: 74  seconds  train loss: 0.20163839966068448 validation loss: 0.20687235525452743
epoch 175 time used: 76  seconds  train loss: 0.20223860003911676 validation loss: 0.20754487398550706
epoch 176 time used: 76  seconds  train loss: 0.2015154148094577 validation loss: 0.2061857575528362
epoch 177 time used: 76  seconds  train loss: 0.2011709569048174 validation loss: 0.20788619831773938
epoch 178 time used: 76  seconds  train loss: 0.20155034579863795 validation loss: 0.20610385843331108
epoch 179 time used: 76  seconds  train loss: 0.20182824954949258 validation loss: 0.20619723321503391
epoch 180 time used: 76  seconds  train loss: 0.20204140808048254 validation loss: 0.20829643455322852
epoch 181 time used: 76  seconds  train loss: 0.2012689413194902 validation loss: 0.20701588295863413
epoch 182 time used: 76  seconds  train loss: 0.20033157107920999 validation loss: 0.2069243106053886
epoch 183 time used: 76  seconds  train loss: 0.2008631878696749 validation loss: 0.20563378414118963
epoch 184 time used: 76  seconds  train loss: 0.20128447959642282 validation loss: 0.20652450884639775
epoch 185 time used: 76  seconds  train loss: 0.20067693599183045 validation loss: 0.20512025253778177
epoch 186 time used: 76  seconds  train loss: 0.20042626697231203 validation loss: 0.2046022037404371
epoch 187 time used: 76  seconds  train loss: 0.20008147483856156 validation loss: 0.2054125195102425
epoch 188 time used: 77  seconds  train loss: 0.20055876051345708 validation loss: 0.20499443267490683
epoch 189 time used: 76  seconds  train loss: 0.199827761031301 validation loss: 0.2042018978580773
epoch 190 time used: 76  seconds  train loss: 0.20022947506637187 validation loss: 0.2056426851921468
epoch 191 time used: 76  seconds  train loss: 0.1998934873762681 validation loss: 0.2046907848534554
epoch 192 time used: 76  seconds  train loss: 0.19969789506967736 validation loss: 0.20441142629026618
epoch 193 time used: 77  seconds  train loss: 0.19963432893638 validation loss: 0.20388676518552043
epoch 194 time used: 76  seconds  train loss: 0.1994608268457552 validation loss: 0.20535768356006348
epoch 195 time used: 76  seconds  train loss: 0.19917938047136358 validation loss: 0.2045264867497252
epoch 196 time used: 76  seconds  train loss: 0.19967169455763645 validation loss: 0.20380160078210824
epoch 197 time used: 77  seconds  train loss: 0.19905226171638588 validation loss: 0.2037356071178395
epoch 198 time used: 76  seconds  train loss: 0.1987248997337312 validation loss: 0.20366382977993774
epoch 199 time used: 77  seconds  train loss: 0.1990114641978603 validation loss: 0.2041682205707498
YS.shape, YS_pred.shape before, (14021, 3, 69, 1) (14021, 3, 69, 1)
YS.shape, YS_pred.shape after, (14021, 3, 69) (14021, 3, 69)
YS_pred.shape before (14021, 3, 69)
YS_pred.shape after (14021, 3, 69)
YS.shape, YS_pred.shape, (14021, 3, 69) (14021, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 1.9476598511e-01, 0.1947659851
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 518.7414407935, 22.7758960481, 12.5657264746, 18.0037528204
Model Training Ended ... Sun Jan  9 04:04:57 2022
pred_METR-LA_GraphWaveNet_220108235733 testing started Sun Jan  9 04:04:57 2022
TEST XS.shape, YS.shape (3507, 2, 69, 12) (3507, 3, 69, 1)
Model Testing Started ... Sun Jan  9 04:04:57 2022
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (3507, 3, 69, 1) (3507, 3, 69, 1)
YS.shape, YS_pred.shape after, (3507, 3, 69) (3507, 3, 69)
YS.shape, YS_pred.shape, (3507, 3, 69) (3507, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 1.9751878731e-01, 0.1975187873
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 567.7184115655, 23.8268422491, 13.1321035088, 20.8540120671
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 473.4656370099, 21.7592655439, 12.2289625256, 19.8233278747
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 568.9887715203, 23.8534855214, 13.1461935045, 21.0209585981
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 660.7002499990, 25.7040901414, 14.0211473422, 21.7177389229
Model Testing Ended ... Sun Jan  9 04:05:29 2022
