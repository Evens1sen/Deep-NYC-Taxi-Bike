data.shape (17544, 69)
pred_METR-LA_GraphWaveNet_2112261653 training started Sun Dec 26 16:53:07 2021
TRAIN XS.shape YS,shape (14021, 1, 69, 12) (14021, 3, 69, 1)
Model Training Started ... Sun Dec 26 16:53:07 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-5                  [-1, 32, 69, 12]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-7                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─linear: 3-10                 [-1, 32, 69, 10]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-11                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-12                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-13                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-14                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-15                 [-1, 32, 69, 9]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-20                 [-1, 32, 69, 7]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-21                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-25                 [-1, 32, 69, 6]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-28                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-30                 [-1, 32, 69, 4]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 3]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-40                 [-1, 32, 69, 1]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 275,779
Trainable params: 275,779
Non-trainable params: 0
Total mult-adds (M): 71.72
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 11.00
Params size (MB): 1.05
Estimated Total Size (MB): 12.06
==========================================================================================
XS_torch.shape:   torch.Size([14021, 1, 69, 12])
YS_torch.shape:   torch.Size([14021, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 12  seconds  train loss: 0.40867086648358014 validation loss: 0.338843788086722
epoch 1 time used: 12  seconds  train loss: 0.3357932864064925 validation loss: 0.3044725230980518
epoch 2 time used: 12  seconds  train loss: 0.30592867768001275 validation loss: 0.28873369849143
epoch 3 time used: 12  seconds  train loss: 0.2899131261742694 validation loss: 0.2735047322712282
epoch 4 time used: 12  seconds  train loss: 0.27752411211007266 validation loss: 0.2682711591872908
epoch 5 time used: 12  seconds  train loss: 0.26915532423418354 validation loss: 0.25938566342735725
epoch 6 time used: 12  seconds  train loss: 0.2605105801556839 validation loss: 0.2527759529254944
epoch 7 time used: 12  seconds  train loss: 0.2555583126680214 validation loss: 0.2485744406496261
epoch 8 time used: 12  seconds  train loss: 0.25079144292578154 validation loss: 0.2441348405188312
epoch 9 time used: 12  seconds  train loss: 0.24681611214820592 validation loss: 0.24222148157532938
epoch 10 time used: 12  seconds  train loss: 0.242506493972496 validation loss: 0.23557242806373974
epoch 11 time used: 12  seconds  train loss: 0.2400379507305337 validation loss: 0.23833211317139902
epoch 12 time used: 12  seconds  train loss: 0.23707767393540824 validation loss: 0.23994513409381177
epoch 13 time used: 12  seconds  train loss: 0.23480021737377457 validation loss: 0.23483746494147958
epoch 14 time used: 12  seconds  train loss: 0.23361613546787507 validation loss: 0.2317433622620545
epoch 15 time used: 12  seconds  train loss: 0.2325866952232402 validation loss: 0.23530249017956456
epoch 16 time used: 12  seconds  train loss: 0.22937875882126355 validation loss: 0.2281870755021122
epoch 17 time used: 12  seconds  train loss: 0.2281845672378565 validation loss: 0.22816601642117934
epoch 18 time used: 12  seconds  train loss: 0.22576563852712547 validation loss: 0.2261048386811666
epoch 19 time used: 12  seconds  train loss: 0.22536817479685536 validation loss: 0.2247107038141589
epoch 20 time used: 12  seconds  train loss: 0.2242147740563314 validation loss: 0.22436660801895128
epoch 21 time used: 12  seconds  train loss: 0.2230345637947175 validation loss: 0.22269945025988055
epoch 22 time used: 12  seconds  train loss: 0.2218428573479744 validation loss: 0.2259760685753836
epoch 23 time used: 12  seconds  train loss: 0.22023190955385774 validation loss: 0.22502128456023782
epoch 24 time used: 12  seconds  train loss: 0.2199049784319386 validation loss: 0.2232891301376372
epoch 25 time used: 12  seconds  train loss: 0.21878609145779854 validation loss: 0.2188611202031221
epoch 26 time used: 12  seconds  train loss: 0.21686561321605874 validation loss: 0.22097167225647027
epoch 27 time used: 12  seconds  train loss: 0.21696945989913183 validation loss: 0.2203238331890759
epoch 28 time used: 12  seconds  train loss: 0.21577869189516277 validation loss: 0.2180768881467024
epoch 29 time used: 12  seconds  train loss: 0.21500898705735283 validation loss: 0.21976489623444323
epoch 30 time used: 12  seconds  train loss: 0.21436449996629056 validation loss: 0.2170856568858206
epoch 31 time used: 12  seconds  train loss: 0.21366881085289469 validation loss: 0.21856281703632352
epoch 32 time used: 12  seconds  train loss: 0.21361610025196617 validation loss: 0.21600086766008778
epoch 33 time used: 12  seconds  train loss: 0.21290749517935356 validation loss: 0.2207847593752779
epoch 34 time used: 12  seconds  train loss: 0.2128867397615021 validation loss: 0.21684329731084928
epoch 35 time used: 12  seconds  train loss: 0.2111883741910659 validation loss: 0.21591587934198886
epoch 36 time used: 12  seconds  train loss: 0.21067488132294282 validation loss: 0.21577983494493122
epoch 37 time used: 12  seconds  train loss: 0.21047775428906146 validation loss: 0.2162794192229688
epoch 38 time used: 12  seconds  train loss: 0.20953709702850126 validation loss: 0.2136058992851277
epoch 39 time used: 12  seconds  train loss: 0.20901130892416533 validation loss: 0.21197388860510202
epoch 40 time used: 12  seconds  train loss: 0.20957164410993645 validation loss: 0.20996944041029086
epoch 41 time used: 12  seconds  train loss: 0.20803869558169705 validation loss: 0.21106015329386804
epoch 42 time used: 12  seconds  train loss: 0.20742037706259295 validation loss: 0.2109032150632099
epoch 43 time used: 12  seconds  train loss: 0.20623947307345997 validation loss: 0.209634860617327
epoch 44 time used: 12  seconds  train loss: 0.20691430065835537 validation loss: 0.20912976508574424
epoch 45 time used: 12  seconds  train loss: 0.20563908688964538 validation loss: 0.20971682375319264
epoch 46 time used: 12  seconds  train loss: 0.20471122657821278 validation loss: 0.20995712669590713
epoch 47 time used: 12  seconds  train loss: 0.2047325890762704 validation loss: 0.2087671950042962
epoch 48 time used: 12  seconds  train loss: 0.20417638747844472 validation loss: 0.2094929640420967
epoch 49 time used: 12  seconds  train loss: 0.2047011594372772 validation loss: 0.20762526322553584
epoch 50 time used: 12  seconds  train loss: 0.2034210934919218 validation loss: 0.20699811583577193
epoch 51 time used: 12  seconds  train loss: 0.20230830395925228 validation loss: 0.20580237132273466
epoch 52 time used: 12  seconds  train loss: 0.20198148193598806 validation loss: 0.2078338976220546
epoch 53 time used: 12  seconds  train loss: 0.2023491992025761 validation loss: 0.2055368423121899
epoch 54 time used: 12  seconds  train loss: 0.2008712049519001 validation loss: 0.20498193195222517
epoch 55 time used: 12  seconds  train loss: 0.201571863298895 validation loss: 0.2055392513445834
epoch 56 time used: 12  seconds  train loss: 0.20101823578313854 validation loss: 0.20527610600980703
epoch 57 time used: 12  seconds  train loss: 0.20011400147898406 validation loss: 0.2057580088062825
epoch 58 time used: 12  seconds  train loss: 0.2000429479032998 validation loss: 0.20541264951501106
epoch 59 time used: 12  seconds  train loss: 0.19996262229748257 validation loss: 0.2061376788584899
epoch 60 time used: 12  seconds  train loss: 0.19909481660022307 validation loss: 0.20565616565980166
epoch 61 time used: 12  seconds  train loss: 0.19792141282173645 validation loss: 0.2045777949243699
epoch 62 time used: 12  seconds  train loss: 0.19810656291734213 validation loss: 0.20258318310251797
epoch 63 time used: 12  seconds  train loss: 0.1979867549334359 validation loss: 0.20637628821155649
epoch 64 time used: 12  seconds  train loss: 0.1972919955854506 validation loss: 0.2059224836073531
epoch 65 time used: 12  seconds  train loss: 0.1969682743300978 validation loss: 0.20422265985932817
epoch 66 time used: 12  seconds  train loss: 0.1964204429093424 validation loss: 0.20314261942030837
epoch 67 time used: 12  seconds  train loss: 0.19687771306952864 validation loss: 0.20401977223630505
epoch 68 time used: 12  seconds  train loss: 0.1954307600899554 validation loss: 0.2018434950371028
epoch 69 time used: 12  seconds  train loss: 0.1954992543486924 validation loss: 0.20334212347669595
epoch 70 time used: 12  seconds  train loss: 0.19474209684248192 validation loss: 0.19991037450174026
epoch 71 time used: 12  seconds  train loss: 0.19433142410978108 validation loss: 0.20401195682801998
epoch 72 time used: 12  seconds  train loss: 0.19389829711996465 validation loss: 0.19953725226457228
epoch 73 time used: 12  seconds  train loss: 0.19394793666299173 validation loss: 0.20090746679818772
epoch 74 time used: 12  seconds  train loss: 0.1933457003350673 validation loss: 0.19934280511656965
epoch 75 time used: 12  seconds  train loss: 0.19297547724898412 validation loss: 0.1985399413724253
epoch 76 time used: 12  seconds  train loss: 0.19276181456123068 validation loss: 0.19876409811220097
epoch 77 time used: 12  seconds  train loss: 0.1927418638789619 validation loss: 0.19923538605417446
epoch 78 time used: 12  seconds  train loss: 0.1922006540493581 validation loss: 0.2010270671815921
epoch 79 time used: 12  seconds  train loss: 0.19215828009292285 validation loss: 0.1985526440725691
epoch 80 time used: 12  seconds  train loss: 0.19153792272863304 validation loss: 0.19774491226441915
epoch 81 time used: 12  seconds  train loss: 0.19146874244803125 validation loss: 0.19758356950382336
epoch 82 time used: 12  seconds  train loss: 0.19111278682781968 validation loss: 0.19883463396151543
epoch 83 time used: 12  seconds  train loss: 0.19077050842813612 validation loss: 0.19694804865601262
epoch 84 time used: 12  seconds  train loss: 0.1908655739497159 validation loss: 0.19856621150758288
epoch 85 time used: 12  seconds  train loss: 0.18993365409458193 validation loss: 0.19706705094437835
epoch 86 time used: 12  seconds  train loss: 0.18986268530052883 validation loss: 0.19758613811379763
epoch 87 time used: 12  seconds  train loss: 0.19016845612736608 validation loss: 0.196001040972918
epoch 88 time used: 12  seconds  train loss: 0.1889907769885559 validation loss: 0.19592872098793795
epoch 89 time used: 12  seconds  train loss: 0.18864024504120358 validation loss: 0.19803322328034634
epoch 90 time used: 12  seconds  train loss: 0.1889286611701675 validation loss: 0.19676075476241398
epoch 91 time used: 12  seconds  train loss: 0.18848636613282388 validation loss: 0.19830252323671538
epoch 92 time used: 12  seconds  train loss: 0.18821736160613523 validation loss: 0.19630318891981705
epoch 93 time used: 12  seconds  train loss: 0.1882830049136892 validation loss: 0.19544622417660487
epoch 94 time used: 12  seconds  train loss: 0.1877844961615778 validation loss: 0.19463267170118048
epoch 95 time used: 12  seconds  train loss: 0.18728700164556114 validation loss: 0.19514543229487713
epoch 96 time used: 12  seconds  train loss: 0.1871302942373405 validation loss: 0.1950205176881702
epoch 97 time used: 12  seconds  train loss: 0.18681122110940984 validation loss: 0.19823896306042527
epoch 98 time used: 12  seconds  train loss: 0.18653012846147426 validation loss: 0.19469441817749314
epoch 99 time used: 12  seconds  train loss: 0.18692403310259428 validation loss: 0.1957123777268617
epoch 100 time used: 12  seconds  train loss: 0.18569920907045445 validation loss: 0.19388740240711522
epoch 101 time used: 12  seconds  train loss: 0.18659837103294247 validation loss: 0.19431701420683625
epoch 102 time used: 12  seconds  train loss: 0.18566489348417 validation loss: 0.19393352760428098
epoch 103 time used: 12  seconds  train loss: 0.18560816733367597 validation loss: 0.1949481429267596
epoch 104 time used: 12  seconds  train loss: 0.1853803612478867 validation loss: 0.19355339904172858
epoch 105 time used: 12  seconds  train loss: 0.1847155610221506 validation loss: 0.19542359335043058
epoch 106 time used: 12  seconds  train loss: 0.18451048547956506 validation loss: 0.1929687427338776
epoch 107 time used: 12  seconds  train loss: 0.1855083613577206 validation loss: 0.19234803708294632
epoch 108 time used: 12  seconds  train loss: 0.1839958933507887 validation loss: 0.19324398559294492
epoch 109 time used: 12  seconds  train loss: 0.18382261937862504 validation loss: 0.1955798733713827
epoch 110 time used: 12  seconds  train loss: 0.18376019573246652 validation loss: 0.19478660293191213
epoch 111 time used: 12  seconds  train loss: 0.18439050440023338 validation loss: 0.19374407842304797
epoch 112 time used: 12  seconds  train loss: 0.1834910941466004 validation loss: 0.1911332516825274
epoch 113 time used: 12  seconds  train loss: 0.18276667969017726 validation loss: 0.19231161130916305
epoch 114 time used: 12  seconds  train loss: 0.1828698794481068 validation loss: 0.19217473994441123
epoch 115 time used: 12  seconds  train loss: 0.18306462117387295 validation loss: 0.1916166024077503
epoch 116 time used: 12  seconds  train loss: 0.1824177622182928 validation loss: 0.19272338221124832
epoch 117 time used: 12  seconds  train loss: 0.18306871817210696 validation loss: 0.19117528347206061
epoch 118 time used: 12  seconds  train loss: 0.18228265697049675 validation loss: 0.1936471531867845
epoch 119 time used: 12  seconds  train loss: 0.18228478047099142 validation loss: 0.19107885209071043
epoch 120 time used: 12  seconds  train loss: 0.1816729647515844 validation loss: 0.1915294503186406
epoch 121 time used: 12  seconds  train loss: 0.1817579412784878 validation loss: 0.1912134147870221
epoch 122 time used: 12  seconds  train loss: 0.1815032413272466 validation loss: 0.18970662105511885
epoch 123 time used: 12  seconds  train loss: 0.1813295106954671 validation loss: 0.19127935746602853
epoch 124 time used: 12  seconds  train loss: 0.18132103019052973 validation loss: 0.19046982531199372
epoch 125 time used: 12  seconds  train loss: 0.18085372593723914 validation loss: 0.19087121687102712
epoch 126 time used: 12  seconds  train loss: 0.18028427556006496 validation loss: 0.1892437510706667
epoch 127 time used: 12  seconds  train loss: 0.1804591022507158 validation loss: 0.19157925989378946
epoch 128 time used: 12  seconds  train loss: 0.18078950192763513 validation loss: 0.19064712702071945
epoch 129 time used: 12  seconds  train loss: 0.18105904158431932 validation loss: 0.1903073996288465
epoch 130 time used: 12  seconds  train loss: 0.1800244002708364 validation loss: 0.18977799348605406
epoch 131 time used: 12  seconds  train loss: 0.1801247322621546 validation loss: 0.1900769199685104
epoch 132 time used: 12  seconds  train loss: 0.18002473073457326 validation loss: 0.18914304285204486
epoch 133 time used: 12  seconds  train loss: 0.17948545848347677 validation loss: 0.1903031353891338
epoch 134 time used: 12  seconds  train loss: 0.17969464107176983 validation loss: 0.19145585851572747
epoch 135 time used: 12  seconds  train loss: 0.17939453911890144 validation loss: 0.18848394994829562
epoch 136 time used: 12  seconds  train loss: 0.17859749248197268 validation loss: 0.18926709973669298
epoch 137 time used: 12  seconds  train loss: 0.17955994125507846 validation loss: 0.18792675825710373
epoch 138 time used: 12  seconds  train loss: 0.17879793507037584 validation loss: 0.18861855298739735
epoch 139 time used: 12  seconds  train loss: 0.17893109349870978 validation loss: 0.1894575168473749
epoch 140 time used: 12  seconds  train loss: 0.17851841714528316 validation loss: 0.1872580391097191
epoch 141 time used: 12  seconds  train loss: 0.17834736467049103 validation loss: 0.1873977829134267
epoch 142 time used: 12  seconds  train loss: 0.17829198980315875 validation loss: 0.18746899670182265
epoch 143 time used: 12  seconds  train loss: 0.17754534266361943 validation loss: 0.18901256212185807
epoch 144 time used: 12  seconds  train loss: 0.178534696695468 validation loss: 0.18891181492900685
epoch 145 time used: 12  seconds  train loss: 0.17793084672288706 validation loss: 0.1907870948008653
epoch 146 time used: 12  seconds  train loss: 0.17802188608869499 validation loss: 0.1885969547105393
epoch 147 time used: 12  seconds  train loss: 0.17800360079945823 validation loss: 0.18898756991640472
epoch 148 time used: 12  seconds  train loss: 0.17831018013696853 validation loss: 0.1872645177316883
epoch 149 time used: 12  seconds  train loss: 0.176595271998949 validation loss: 0.18693691736041512
epoch 150 time used: 12  seconds  train loss: 0.17668277223451465 validation loss: 0.18779425489616883
epoch 151 time used: 12  seconds  train loss: 0.1772478991420408 validation loss: 0.18787174135939572
epoch 152 time used: 12  seconds  train loss: 0.17634123341245064 validation loss: 0.1873374061708918
epoch 153 time used: 12  seconds  train loss: 0.17656243358561688 validation loss: 0.18703534283674722
epoch 154 time used: 12  seconds  train loss: 0.17661648012641823 validation loss: 0.1876417904140197
epoch 155 time used: 12  seconds  train loss: 0.17622284622292664 validation loss: 0.18692689448068023
epoch 156 time used: 12  seconds  train loss: 0.17615875029917605 validation loss: 0.1864380817615979
epoch 157 time used: 12  seconds  train loss: 0.17681089518783066 validation loss: 0.18870151533409996
epoch 158 time used: 12  seconds  train loss: 0.1763761169773614 validation loss: 0.18802067786200144
epoch 159 time used: 12  seconds  train loss: 0.17600519101511666 validation loss: 0.18747285333994926
epoch 160 time used: 12  seconds  train loss: 0.1761241304172846 validation loss: 0.18650571247100559
epoch 161 time used: 12  seconds  train loss: 0.1763610875894163 validation loss: 0.18949617317963244
epoch 162 time used: 12  seconds  train loss: 0.17605260863322017 validation loss: 0.18694171925748476
epoch 163 time used: 12  seconds  train loss: 0.17536497564046827 validation loss: 0.1860760007578512
epoch 164 time used: 12  seconds  train loss: 0.17561382317158233 validation loss: 0.1868573185959613
epoch 165 time used: 12  seconds  train loss: 0.17499423705291622 validation loss: 0.1864129529210818
epoch 166 time used: 12  seconds  train loss: 0.17508521905386917 validation loss: 0.18552965470640168
epoch 167 time used: 12  seconds  train loss: 0.1747096179069585 validation loss: 0.18682040618408494
epoch 168 time used: 12  seconds  train loss: 0.174914744818953 validation loss: 0.18603735184642292
epoch 169 time used: 12  seconds  train loss: 0.17461869078814343 validation loss: 0.1853154595331403
epoch 170 time used: 12  seconds  train loss: 0.1742241923257898 validation loss: 0.18485446649147183
epoch 171 time used: 12  seconds  train loss: 0.17441552830784104 validation loss: 0.18497916050489058
epoch 172 time used: 12  seconds  train loss: 0.1745678478463838 validation loss: 0.18601273523013523
epoch 173 time used: 12  seconds  train loss: 0.17506668674156803 validation loss: 0.18422633240342617
epoch 174 time used: 11  seconds  train loss: 0.17482364947297577 validation loss: 0.18573637446096403
epoch 175 time used: 9  seconds  train loss: 0.17387874409396056 validation loss: 0.1853814057738048
epoch 176 time used: 7  seconds  train loss: 0.17387481706224828 validation loss: 0.18584301437878703
epoch 177 time used: 7  seconds  train loss: 0.17411319711307846 validation loss: 0.18569510085407284
epoch 178 time used: 7  seconds  train loss: 0.17327154513034285 validation loss: 0.1871222901942726
epoch 179 time used: 7  seconds  train loss: 0.17346293597995632 validation loss: 0.18449879045392606
epoch 180 time used: 7  seconds  train loss: 0.17356157969934838 validation loss: 0.18513063080842604
epoch 181 time used: 7  seconds  train loss: 0.1729957658905605 validation loss: 0.1841452309167936
epoch 182 time used: 7  seconds  train loss: 0.17317891071839328 validation loss: 0.1849268091894597
epoch 183 time used: 7  seconds  train loss: 0.17290130863467218 validation loss: 0.1843608447520038
epoch 184 time used: 7  seconds  train loss: 0.1724538461933472 validation loss: 0.18435199636938362
epoch 185 time used: 7  seconds  train loss: 0.1732388896558508 validation loss: 0.18425087538944676
epoch 186 time used: 7  seconds  train loss: 0.17272452381872222 validation loss: 0.1865660798886267
epoch 187 time used: 7  seconds  train loss: 0.1729390215496695 validation loss: 0.18612265051329266
epoch 188 time used: 7  seconds  train loss: 0.17255342496424805 validation loss: 0.18467484659388347
epoch 189 time used: 7  seconds  train loss: 0.17232574549217275 validation loss: 0.18437802622437954
epoch 190 time used: 8  seconds  train loss: 0.17241278004580224 validation loss: 0.18361855146548983
epoch 191 time used: 7  seconds  train loss: 0.17281233540450397 validation loss: 0.1847943852815503
epoch 192 time used: 8  seconds  train loss: 0.17236061741600683 validation loss: 0.18483154623595496
epoch 193 time used: 7  seconds  train loss: 0.17192302851712699 validation loss: 0.18420870177962068
epoch 194 time used: 7  seconds  train loss: 0.17218238210538175 validation loss: 0.1833569838262189
epoch 195 time used: 7  seconds  train loss: 0.1716588667609383 validation loss: 0.18323025936170503
epoch 196 time used: 7  seconds  train loss: 0.17215509240445384 validation loss: 0.18372583117270158
epoch 197 time used: 7  seconds  train loss: 0.17231479741907446 validation loss: 0.1837877366315686
epoch 198 time used: 7  seconds  train loss: 0.17161358431841597 validation loss: 0.18283557672535972
epoch 199 time used: 7  seconds  train loss: 0.17126176188774905 validation loss: 0.18327525475673925
YS.shape, YS_pred.shape before, (14021, 3, 69, 1) (14021, 3, 69, 1)
YS.shape, YS_pred.shape after, (14021, 3, 69) (14021, 3, 69)
YS_pred.shape before (14021, 3, 69)
YS_pred.shape after (14021, 3, 69)
YS.shape, YS_pred.shape, (14021, 3, 69) (14021, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 1.6797640277e-01, 0.1679764028
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 349.4468422099, 18.6934973242, 10.7089601380, 15.7978718497
Model Training Ended ... Sun Dec 26 17:32:15 2021
pred_METR-LA_GraphWaveNet_2112261653 testing started Sun Dec 26 17:32:15 2021
TEST XS.shape, YS.shape (3507, 1, 69, 12) (3507, 3, 69, 1)
Model Testing Started ... Sun Dec 26 17:32:15 2021
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (3507, 3, 69, 1) (3507, 3, 69, 1)
YS.shape, YS_pred.shape after, (3507, 3, 69) (3507, 3, 69)
YS.shape, YS_pred.shape, (3507, 3, 69) (3507, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 1.7779746051e-01, 0.1777974605
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 387.7371075271, 19.6910413012, 11.2446515463, 18.1683809078
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 325.4677626212, 18.0407251135, 10.7460394307, 18.3296271936
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 390.4949237375, 19.7609444040, 11.2381809095, 18.1133240878
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 447.2478468576, 21.1482350767, 11.7497287361, 18.0621953607
Model Testing Ended ... Sun Dec 26 17:32:16 2021
