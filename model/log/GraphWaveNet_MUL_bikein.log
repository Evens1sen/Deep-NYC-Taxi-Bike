data.shape (17544, 69)
pred_METR-LA_GraphWaveNet_2201031826 training started Mon Jan  3 18:26:39 2022
TRAIN XS.shape YS,shape (14021, 1, 69, 12) (14021, 3, 69, 1)
Model Training Started ... Mon Jan  3 18:26:39 2022
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-5                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-7                  [-1, 32, 69, 12]          7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-10                  [-1, 32, 69, 10]          --
|    |    └─nconv: 3-11                  [-1, 32, 69, 10]          --
|    |    └─nconv: 3-12                  [-1, 32, 69, 10]          --
|    |    └─nconv: 3-13                  [-1, 32, 69, 10]          --
|    |    └─linear: 3-14                 [-1, 32, 69, 10]          7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-15                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-20                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-21                 [-1, 32, 69, 9]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-25                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-28                 [-1, 32, 69, 7]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-30                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 6]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-40                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-41                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-42                 [-1, 32, 69, 4]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-43                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-44                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-45                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-46                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-47                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-48                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-49                 [-1, 32, 69, 3]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-50                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-51                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-52                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-53                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-54                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-55                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-56                 [-1, 32, 69, 1]           7,200
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 292,163
Trainable params: 292,163
Non-trainable params: 0
Total mult-adds (M): 79.10
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 11.00
Params size (MB): 1.11
Estimated Total Size (MB): 12.12
==========================================================================================/home/cseadmin/mhy/model/GraphWaveNet.py:331: RuntimeWarning: divide by zero encountered in power
  d_inv_sqrt = np.power(d, -0.5).flatten()

XS_torch.shape:   torch.Size([14021, 1, 69, 12])
YS_torch.shape:   torch.Size([14021, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 10  seconds  train loss: 0.30290898693805024 validation loss: 0.35591380531898037
epoch 1 time used: 9  seconds  train loss: 0.23889720422420122 validation loss: 0.34996900191935415
epoch 2 time used: 10  seconds  train loss: 0.2153861525443932 validation loss: 0.3355742765880624
epoch 3 time used: 9  seconds  train loss: 0.20289199457500515 validation loss: 0.34394543524884663
epoch 4 time used: 10  seconds  train loss: 0.19648704411328946 validation loss: 0.3270946830868109
epoch 5 time used: 10  seconds  train loss: 0.19267282456421952 validation loss: 0.3274242146247738
epoch 6 time used: 10  seconds  train loss: 0.18732796296025472 validation loss: 0.31996071829975364
epoch 7 time used: 10  seconds  train loss: 0.18431956492750662 validation loss: 0.3177298945967157
epoch 8 time used: 10  seconds  train loss: 0.18151733052334104 validation loss: 0.31763570846249156
epoch 9 time used: 10  seconds  train loss: 0.17991206677157442 validation loss: 0.30796253582578487
epoch 10 time used: 9  seconds  train loss: 0.1783833999732126 validation loss: 0.30367926766174697
epoch 11 time used: 9  seconds  train loss: 0.17605466471166925 validation loss: 0.29754974185162386
epoch 12 time used: 10  seconds  train loss: 0.17339005351144327 validation loss: 0.2939794135141291
epoch 13 time used: 9  seconds  train loss: 0.17218581193776872 validation loss: 0.29471702986761833
epoch 14 time used: 9  seconds  train loss: 0.17121318718743395 validation loss: 0.29061965864519357
epoch 15 time used: 10  seconds  train loss: 0.17065460505258542 validation loss: 0.29624392361689894
epoch 16 time used: 10  seconds  train loss: 0.16844955887882337 validation loss: 0.28740820271657386
epoch 17 time used: 9  seconds  train loss: 0.167655191190825 validation loss: 0.2899844366961456
epoch 18 time used: 10  seconds  train loss: 0.16735635462202153 validation loss: 0.30501667680022243
epoch 19 time used: 9  seconds  train loss: 0.16604825285365693 validation loss: 0.2949490067588895
epoch 20 time used: 9  seconds  train loss: 0.16564574237654175 validation loss: 0.29207934567537974
epoch 21 time used: 9  seconds  train loss: 0.1630394574452737 validation loss: 0.2902181857970532
epoch 22 time used: 9  seconds  train loss: 0.16360405878928183 validation loss: 0.3062666486279324
epoch 23 time used: 9  seconds  train loss: 0.16234510080760722 validation loss: 0.2824523799329639
epoch 24 time used: 10  seconds  train loss: 0.16167263125980721 validation loss: 0.28399462735251707
epoch 25 time used: 10  seconds  train loss: 0.16070276440006145 validation loss: 0.3001758750683229
epoch 26 time used: 10  seconds  train loss: 0.1602635987231737 validation loss: 0.28976803560700337
epoch 27 time used: 9  seconds  train loss: 0.15989906585951136 validation loss: 0.2859108956691135
epoch 28 time used: 10  seconds  train loss: 0.15934853509850716 validation loss: 0.28751725361337677
epoch 29 time used: 9  seconds  train loss: 0.158204966010043 validation loss: 0.2933329475381615
epoch 30 time used: 9  seconds  train loss: 0.157055133128345 validation loss: 0.29031083637214156
epoch 31 time used: 10  seconds  train loss: 0.15658182744331534 validation loss: 0.284876488034411
epoch 32 time used: 10  seconds  train loss: 0.15693884838723499 validation loss: 0.28561368909347284
Early stopping at epoch: 33
YS.shape, YS_pred.shape before, (14021, 3, 69, 1) (14021, 3, 69, 1)
YS.shape, YS_pred.shape after, (14021, 3, 69) (14021, 3, 69)
YS_pred.shape before (14021, 3, 69)
YS_pred.shape after (14021, 3, 69)
YS.shape, YS_pred.shape, (14021, 3, 69) (14021, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 1.5361911260e-01, 0.1536191126
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 127.8483717022, 11.3070054259, 6.3619931833, 40.7192986084
Model Training Ended ... Mon Jan  3 18:32:30 2022
pred_METR-LA_GraphWaveNet_2201031826 testing started Mon Jan  3 18:32:30 2022
TEST XS.shape, YS.shape (3507, 1, 69, 12) (3507, 3, 69, 1)
Model Testing Started ... Mon Jan  3 18:32:30 2022
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (3507, 3, 69, 1) (3507, 3, 69, 1)
YS.shape, YS_pred.shape after, (3507, 3, 69) (3507, 3, 69)
YS.shape, YS_pred.shape, (3507, 3, 69) (3507, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 3.2913094171e-01, 0.3291309417
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 255.7778209123, 15.9930553964, 9.3012201831, 49.4476399076
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 142.3022912728, 11.9290524046, 7.2534559908, 39.8078437161
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 263.0899630848, 16.2200481838, 9.4677513036, 49.4040808406
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 361.9423274596, 19.0247819294, 11.1824737376, 59.1310963101
Model Testing Ended ... Mon Jan  3 18:32:32 2022
