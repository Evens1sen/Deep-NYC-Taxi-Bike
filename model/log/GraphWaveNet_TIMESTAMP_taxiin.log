data.shape (17544, 69)
pred_METR-LA_GraphWaveNet_2201030132 training started Mon Jan  3 01:32:55 2022
TRAIN XS.shape YS,shape (14021, 2, 69, 12) (14021, 3, 69, 1)
Model Training Started ... Mon Jan  3 01:32:55 2022
TIMESTEP_IN, TIMESTEP_OUT 12 3
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 69, 13]          96
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-1                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-2                       [-1, 32, 69, 12]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-3                       [-1, 256, 69, 12]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-4                          [-1, 32, 69, 12]          --
|    |    └─nconv: 3-1                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-2                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-3                   [-1, 32, 69, 12]          --
|    |    └─nconv: 3-4                   [-1, 32, 69, 12]          --
|    |    └─linear: 3-5                  [-1, 32, 69, 12]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-5                  [-1, 32, 69, 12]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-6                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-7                       [-1, 32, 69, 10]          2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-8                       [-1, 256, 69, 10]         8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-9                          [-1, 32, 69, 10]          --
|    |    └─nconv: 3-6                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-7                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-8                   [-1, 32, 69, 10]          --
|    |    └─nconv: 3-9                   [-1, 32, 69, 10]          --
|    |    └─linear: 3-10                 [-1, 32, 69, 10]          5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-10                 [-1, 32, 69, 10]          64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-11                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-12                      [-1, 32, 69, 9]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-13                      [-1, 256, 69, 9]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-14                         [-1, 32, 69, 9]           --
|    |    └─nconv: 3-11                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-12                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-13                  [-1, 32, 69, 9]           --
|    |    └─nconv: 3-14                  [-1, 32, 69, 9]           --
|    |    └─linear: 3-15                 [-1, 32, 69, 9]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-15                 [-1, 32, 69, 9]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-16                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-17                      [-1, 32, 69, 7]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-18                      [-1, 256, 69, 7]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-19                         [-1, 32, 69, 7]           --
|    |    └─nconv: 3-16                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-17                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-18                  [-1, 32, 69, 7]           --
|    |    └─nconv: 3-19                  [-1, 32, 69, 7]           --
|    |    └─linear: 3-20                 [-1, 32, 69, 7]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-20                 [-1, 32, 69, 7]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-21                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-22                      [-1, 32, 69, 6]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-23                      [-1, 256, 69, 6]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-24                         [-1, 32, 69, 6]           --
|    |    └─nconv: 3-21                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-22                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-23                  [-1, 32, 69, 6]           --
|    |    └─nconv: 3-24                  [-1, 32, 69, 6]           --
|    |    └─linear: 3-25                 [-1, 32, 69, 6]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-25                 [-1, 32, 69, 6]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-26                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-27                      [-1, 32, 69, 4]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-28                      [-1, 256, 69, 4]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-29                         [-1, 32, 69, 4]           --
|    |    └─nconv: 3-26                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-27                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-28                  [-1, 32, 69, 4]           --
|    |    └─nconv: 3-29                  [-1, 32, 69, 4]           --
|    |    └─linear: 3-30                 [-1, 32, 69, 4]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-30                 [-1, 32, 69, 4]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-31                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-32                      [-1, 32, 69, 3]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-33                      [-1, 256, 69, 3]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-34                         [-1, 32, 69, 3]           --
|    |    └─nconv: 3-31                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-32                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-33                  [-1, 32, 69, 3]           --
|    |    └─nconv: 3-34                  [-1, 32, 69, 3]           --
|    |    └─linear: 3-35                 [-1, 32, 69, 3]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-35                 [-1, 32, 69, 3]           64
├─ModuleList: 1                          []                        --
|    └─Conv2d: 2-36                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-37                      [-1, 32, 69, 1]           2,080
├─ModuleList: 1                          []                        --
|    └─Conv1d: 2-38                      [-1, 256, 69, 1]          8,448
├─ModuleList: 1                          []                        --
|    └─gcn: 2-39                         [-1, 32, 69, 1]           --
|    |    └─nconv: 3-36                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-37                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-38                  [-1, 32, 69, 1]           --
|    |    └─nconv: 3-39                  [-1, 32, 69, 1]           --
|    |    └─linear: 3-40                 [-1, 32, 69, 1]           5,152
├─ModuleList: 1                          []                        --
|    └─BatchNorm2d: 2-40                 [-1, 32, 69, 1]           64
├─Conv2d: 1-2                            [-1, 512, 69, 1]          131,584
├─Conv2d: 1-3                            [-1, 3, 69, 1]            1,539
==========================================================================================
Total params: 275,811
Trainable params: 275,811
Non-trainable params: 0
Total mult-adds (M): 71.75
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 11.00
Params size (MB): 1.05
Estimated Total Size (MB): 12.06
==========================================================================================
XS_torch.shape:   torch.Size([14021, 2, 69, 12])
YS_torch.shape:   torch.Size([14021, 3, 69, 1])
LOSS is : MAE
epoch 0 time used: 24  seconds  train loss: 0.4049104475940055 validation loss: 0.33449561692481034
epoch 1 time used: 24  seconds  train loss: 0.3415094500921975 validation loss: 0.31951405595046617
epoch 2 time used: 24  seconds  train loss: 0.3151670918816031 validation loss: 0.2914919385859712
epoch 3 time used: 24  seconds  train loss: 0.2983641504833276 validation loss: 0.3002029895204445
epoch 4 time used: 24  seconds  train loss: 0.2887855879658785 validation loss: 0.2745029291151866
epoch 5 time used: 24  seconds  train loss: 0.2806174829529363 validation loss: 0.2655183411603374
epoch 6 time used: 24  seconds  train loss: 0.2754296700846383 validation loss: 0.2664772110262804
epoch 7 time used: 24  seconds  train loss: 0.2697483133640047 validation loss: 0.2692253158320989
epoch 8 time used: 24  seconds  train loss: 0.2678505868195788 validation loss: 0.25996556777785457
epoch 9 time used: 24  seconds  train loss: 0.2613869437107948 validation loss: 0.2612529541687223
epoch 10 time used: 24  seconds  train loss: 0.2588820184116687 validation loss: 0.25082852917096987
epoch 11 time used: 24  seconds  train loss: 0.2569673676851482 validation loss: 0.2535096516846522
epoch 12 time used: 24  seconds  train loss: 0.25336274508548395 validation loss: 0.24589882404275165
epoch 13 time used: 24  seconds  train loss: 0.25168082766164424 validation loss: 0.2442403160124864
epoch 14 time used: 23  seconds  train loss: 0.2495852099554835 validation loss: 0.24574274560824436
epoch 15 time used: 18  seconds  train loss: 0.24668452901602336 validation loss: 0.24382733804834142
epoch 16 time used: 18  seconds  train loss: 0.24688304036632205 validation loss: 0.24278211231511862
epoch 17 time used: 18  seconds  train loss: 0.24470917835350647 validation loss: 0.2406495198887957
epoch 18 time used: 13  seconds  train loss: 0.2432707649587924 validation loss: 0.24326526700464304
epoch 19 time used: 12  seconds  train loss: 0.2415766070205457 validation loss: 0.239026475364116
epoch 20 time used: 12  seconds  train loss: 0.24107770156327854 validation loss: 0.23779494062499598
epoch 21 time used: 12  seconds  train loss: 0.24058448897148135 validation loss: 0.2447093056904814
epoch 22 time used: 12  seconds  train loss: 0.2392140519776405 validation loss: 0.24280832236110994
epoch 23 time used: 12  seconds  train loss: 0.23761291195097053 validation loss: 0.23275420673221298
epoch 24 time used: 12  seconds  train loss: 0.23784847410816612 validation loss: 0.24024166643653538
epoch 25 time used: 12  seconds  train loss: 0.23733426904518984 validation loss: 0.23448332518560167
epoch 26 time used: 12  seconds  train loss: 0.23678024918725213 validation loss: 0.2314538022092051
epoch 27 time used: 12  seconds  train loss: 0.23444442081750702 validation loss: 0.2299113419487078
epoch 28 time used: 12  seconds  train loss: 0.23330770147752405 validation loss: 0.23499322876002676
epoch 29 time used: 12  seconds  train loss: 0.23277283049111727 validation loss: 0.23087795426419852
epoch 30 time used: 12  seconds  train loss: 0.2319929202770153 validation loss: 0.23729597607545694
epoch 31 time used: 12  seconds  train loss: 0.231403905612893 validation loss: 0.22778169826072622
epoch 32 time used: 12  seconds  train loss: 0.23071662275127297 validation loss: 0.23406188065877861
epoch 33 time used: 12  seconds  train loss: 0.23052956499122898 validation loss: 0.2308387776918569
epoch 34 time used: 12  seconds  train loss: 0.22967659605027488 validation loss: 0.2270999837962138
epoch 35 time used: 12  seconds  train loss: 0.2290318693842995 validation loss: 0.23118517759930252
epoch 36 time used: 12  seconds  train loss: 0.22793863332345426 validation loss: 0.22927626282299715
epoch 37 time used: 12  seconds  train loss: 0.22852481195698898 validation loss: 0.2250376012552417
epoch 38 time used: 12  seconds  train loss: 0.22673340515395426 validation loss: 0.22685552012287952
epoch 39 time used: 12  seconds  train loss: 0.22717239917354629 validation loss: 0.22652904610258473
epoch 40 time used: 12  seconds  train loss: 0.2257823195341242 validation loss: 0.2240434941467529
epoch 41 time used: 12  seconds  train loss: 0.22568023109090107 validation loss: 0.22756509047641255
epoch 42 time used: 12  seconds  train loss: 0.22466157419035557 validation loss: 0.22608854557470942
epoch 43 time used: 12  seconds  train loss: 0.22491618301956282 validation loss: 0.2263157382496955
epoch 44 time used: 12  seconds  train loss: 0.2240435281239467 validation loss: 0.22444227071775413
epoch 45 time used: 12  seconds  train loss: 0.22344149240539485 validation loss: 0.2258177600414224
epoch 46 time used: 12  seconds  train loss: 0.22313491230995133 validation loss: 0.22251258800693463
epoch 47 time used: 12  seconds  train loss: 0.2219163605103401 validation loss: 0.22145007407060024
epoch 48 time used: 12  seconds  train loss: 0.22167553835498965 validation loss: 0.21989446017345018
epoch 49 time used: 12  seconds  train loss: 0.22078083132955123 validation loss: 0.2273954690624766
epoch 50 time used: 12  seconds  train loss: 0.22076264509149587 validation loss: 0.2206901149772197
epoch 51 time used: 12  seconds  train loss: 0.22005910045711155 validation loss: 0.22271378304335435
epoch 52 time used: 12  seconds  train loss: 0.22008228156731421 validation loss: 0.21972695985013121
epoch 53 time used: 12  seconds  train loss: 0.2198516346604108 validation loss: 0.2239368227095313
epoch 54 time used: 12  seconds  train loss: 0.21847223768142524 validation loss: 0.2228902827839952
epoch 55 time used: 12  seconds  train loss: 0.2187025837617236 validation loss: 0.22071063866189597
epoch 56 time used: 12  seconds  train loss: 0.21849624132892384 validation loss: 0.2202598798363398
epoch 57 time used: 12  seconds  train loss: 0.21776435045901363 validation loss: 0.22123602348875468
epoch 58 time used: 12  seconds  train loss: 0.21716283381296206 validation loss: 0.21779511277327454
epoch 59 time used: 12  seconds  train loss: 0.21647753476863346 validation loss: 0.21977302914881666
epoch 60 time used: 12  seconds  train loss: 0.21630595550111112 validation loss: 0.2198446614447826
epoch 61 time used: 12  seconds  train loss: 0.2159298221976352 validation loss: 0.2175222053503351
epoch 62 time used: 12  seconds  train loss: 0.21523916442949298 validation loss: 0.21735934608844915
epoch 63 time used: 12  seconds  train loss: 0.2144862248507314 validation loss: 0.2167921007716581
epoch 64 time used: 12  seconds  train loss: 0.2149782928516393 validation loss: 0.21836575818143433
epoch 65 time used: 12  seconds  train loss: 0.21464553598301161 validation loss: 0.22270761868882982
epoch 66 time used: 12  seconds  train loss: 0.2140202906734593 validation loss: 0.21611600275285844
epoch 67 time used: 12  seconds  train loss: 0.21382920485795184 validation loss: 0.21492630135346602
epoch 68 time used: 12  seconds  train loss: 0.21305975445734782 validation loss: 0.21406529716301562
epoch 69 time used: 12  seconds  train loss: 0.21285482345651174 validation loss: 0.21550728084866957
epoch 70 time used: 12  seconds  train loss: 0.21210815638235736 validation loss: 0.21657172877381886
epoch 71 time used: 12  seconds  train loss: 0.21117597683792905 validation loss: 0.21520005844860707
epoch 72 time used: 12  seconds  train loss: 0.21131158956087565 validation loss: 0.21258001406058133
epoch 73 time used: 12  seconds  train loss: 0.2115735092583253 validation loss: 0.21640429051175364
epoch 74 time used: 12  seconds  train loss: 0.21138633550534933 validation loss: 0.21373548178045804
epoch 75 time used: 12  seconds  train loss: 0.2110450030111668 validation loss: 0.2156461413271823
epoch 76 time used: 12  seconds  train loss: 0.20977707079423147 validation loss: 0.21226495230667128
epoch 77 time used: 12  seconds  train loss: 0.20972465717679792 validation loss: 0.21612199263714138
epoch 78 time used: 12  seconds  train loss: 0.2097435371229382 validation loss: 0.2119788477336483
epoch 79 time used: 12  seconds  train loss: 0.20835712583651167 validation loss: 0.2118161693342876
epoch 80 time used: 12  seconds  train loss: 0.20859603874353777 validation loss: 0.2117670895845225
epoch 81 time used: 12  seconds  train loss: 0.20850193330955535 validation loss: 0.21300428309273325
epoch 82 time used: 12  seconds  train loss: 0.20834129444834537 validation loss: 0.2134322477828688
epoch 83 time used: 12  seconds  train loss: 0.20838083046964298 validation loss: 0.21227084708023397
epoch 84 time used: 12  seconds  train loss: 0.20696999649582526 validation loss: 0.21052745917118146
epoch 85 time used: 12  seconds  train loss: 0.20719124728046726 validation loss: 0.21035178720577064
epoch 86 time used: 12  seconds  train loss: 0.2061337725537819 validation loss: 0.2096889375603274
epoch 87 time used: 12  seconds  train loss: 0.20681290106467093 validation loss: 0.2102620134388319
epoch 88 time used: 12  seconds  train loss: 0.20559725792119588 validation loss: 0.20964189014874113
epoch 89 time used: 12  seconds  train loss: 0.2059017238882803 validation loss: 0.2092088783511555
epoch 90 time used: 12  seconds  train loss: 0.20556904602447237 validation loss: 0.21239301309848063
epoch 91 time used: 12  seconds  train loss: 0.20581297172196417 validation loss: 0.20863619411052872
epoch 92 time used: 12  seconds  train loss: 0.20494887023377115 validation loss: 0.21112551473408375
epoch 93 time used: 12  seconds  train loss: 0.2046658626821634 validation loss: 0.20937672709643468
epoch 94 time used: 12  seconds  train loss: 0.20448311701791078 validation loss: 0.20859126572396777
epoch 95 time used: 12  seconds  train loss: 0.20425390875082977 validation loss: 0.20664385364046114
epoch 96 time used: 12  seconds  train loss: 0.20403947852938192 validation loss: 0.21130125044382306
epoch 97 time used: 12  seconds  train loss: 0.20387887724416826 validation loss: 0.20731049928234022
epoch 98 time used: 12  seconds  train loss: 0.2031326683843645 validation loss: 0.2078144357109913
epoch 99 time used: 12  seconds  train loss: 0.20387301718640646 validation loss: 0.2084692926557827
epoch 100 time used: 12  seconds  train loss: 0.20267526237436798 validation loss: 0.20652215679203248
epoch 101 time used: 12  seconds  train loss: 0.2026328380639599 validation loss: 0.20687076027775517
epoch 102 time used: 12  seconds  train loss: 0.20259283462622518 validation loss: 0.20675979391445926
epoch 103 time used: 12  seconds  train loss: 0.20235401844313683 validation loss: 0.20738416911871585
epoch 104 time used: 12  seconds  train loss: 0.20169323923283072 validation loss: 0.20751480135112507
epoch 105 time used: 12  seconds  train loss: 0.20144688497158694 validation loss: 0.20643564840248496
epoch 106 time used: 12  seconds  train loss: 0.20182889152863612 validation loss: 0.2066896255874525
epoch 107 time used: 12  seconds  train loss: 0.20130946679829695 validation loss: 0.20757527826210465
epoch 108 time used: 12  seconds  train loss: 0.20083228013085588 validation loss: 0.20649486767416061
epoch 109 time used: 12  seconds  train loss: 0.20104309641016707 validation loss: 0.20891589910658984
epoch 110 time used: 12  seconds  train loss: 0.2007895563250844 validation loss: 0.2054491357519772
epoch 111 time used: 12  seconds  train loss: 0.20009693307094556 validation loss: 0.20663084140758275
epoch 112 time used: 12  seconds  train loss: 0.20010716930872305 validation loss: 0.2067998458641431
epoch 113 time used: 12  seconds  train loss: 0.19980671805553418 validation loss: 0.20635067427151554
epoch 114 time used: 12  seconds  train loss: 0.1995999630398497 validation loss: 0.20511059882092733
epoch 115 time used: 12  seconds  train loss: 0.1997936110728565 validation loss: 0.2050018814534238
epoch 116 time used: 12  seconds  train loss: 0.19919903095863833 validation loss: 0.205406632718534
epoch 117 time used: 12  seconds  train loss: 0.19894505329345077 validation loss: 0.20358470368745732
epoch 118 time used: 12  seconds  train loss: 0.1993580261153665 validation loss: 0.20757930233216054
epoch 119 time used: 12  seconds  train loss: 0.19852993970862576 validation loss: 0.20858922936511054
epoch 120 time used: 12  seconds  train loss: 0.19892314425267263 validation loss: 0.20423814599947868
epoch 121 time used: 12  seconds  train loss: 0.1983440306012157 validation loss: 0.20428321822942222
epoch 122 time used: 12  seconds  train loss: 0.19748996294376553 validation loss: 0.20556289669927433
epoch 123 time used: 12  seconds  train loss: 0.19810999683576647 validation loss: 0.20295972461640596
epoch 124 time used: 12  seconds  train loss: 0.19766134021722964 validation loss: 0.2030916338689791
epoch 125 time used: 12  seconds  train loss: 0.19694509709701502 validation loss: 0.20358423500216083
epoch 126 time used: 12  seconds  train loss: 0.1971595009268399 validation loss: 0.20472139829033387
epoch 127 time used: 12  seconds  train loss: 0.19742172696534452 validation loss: 0.20394402779787524
epoch 128 time used: 12  seconds  train loss: 0.19680272131662707 validation loss: 0.20266891149745556
epoch 129 time used: 12  seconds  train loss: 0.19619573472006374 validation loss: 0.20334015336977843
epoch 130 time used: 12  seconds  train loss: 0.19637535805903547 validation loss: 0.20181332550692135
epoch 131 time used: 12  seconds  train loss: 0.1956224919269168 validation loss: 0.2024334185781713
epoch 132 time used: 12  seconds  train loss: 0.19598673734926889 validation loss: 0.20195839495843843
epoch 133 time used: 12  seconds  train loss: 0.19627637131170608 validation loss: 0.20484193538980217
epoch 134 time used: 12  seconds  train loss: 0.19576112517402583 validation loss: 0.20361206329045675
epoch 135 time used: 12  seconds  train loss: 0.19524908703723015 validation loss: 0.20291834530732458
epoch 136 time used: 12  seconds  train loss: 0.19547037026724365 validation loss: 0.2016836432341637
epoch 137 time used: 12  seconds  train loss: 0.1947052366023426 validation loss: 0.20196358799186354
epoch 138 time used: 12  seconds  train loss: 0.19509778934326552 validation loss: 0.20108607146172813
epoch 139 time used: 12  seconds  train loss: 0.19476612238744823 validation loss: 0.20281364773418722
epoch 140 time used: 12  seconds  train loss: 0.19472921171559937 validation loss: 0.20139681905321033
epoch 141 time used: 12  seconds  train loss: 0.19471365518996722 validation loss: 0.20207526771531265
epoch 142 time used: 12  seconds  train loss: 0.19409420810345915 validation loss: 0.20034373870796296
epoch 143 time used: 12  seconds  train loss: 0.19421490899584445 validation loss: 0.20105370203393294
epoch 144 time used: 12  seconds  train loss: 0.19388312972015614 validation loss: 0.200081047182823
epoch 145 time used: 12  seconds  train loss: 0.19389441079801092 validation loss: 0.20122289002213692
epoch 146 time used: 12  seconds  train loss: 0.19421972950448577 validation loss: 0.20354613722968767
epoch 147 time used: 12  seconds  train loss: 0.1935225246024124 validation loss: 0.20091342887773694
epoch 148 time used: 12  seconds  train loss: 0.1932342998855931 validation loss: 0.20162141357941146
epoch 149 time used: 12  seconds  train loss: 0.19333260855963924 validation loss: 0.20207519523259646
epoch 150 time used: 12  seconds  train loss: 0.19301777340066056 validation loss: 0.2009087627146901
epoch 151 time used: 12  seconds  train loss: 0.19351731703768812 validation loss: 0.20327477690939624
epoch 152 time used: 12  seconds  train loss: 0.19312008459365132 validation loss: 0.20078980680438224
epoch 153 time used: 12  seconds  train loss: 0.1926648040324265 validation loss: 0.20072977459913516
Early stopping at epoch: 154
YS.shape, YS_pred.shape before, (14021, 3, 69, 1) (14021, 3, 69, 1)
YS.shape, YS_pred.shape after, (14021, 3, 69) (14021, 3, 69)
YS_pred.shape before (14021, 3, 69)
YS_pred.shape after (14021, 3, 69)
YS.shape, YS_pred.shape, (14021, 3, 69) (14021, 3, 69)
****************************************
GraphWaveNet, train, Torch MSE, 1.8782137433e-01, 0.1878213743
GraphWaveNet, train, MSE, RMSE, MAE, MAPE, 502.0224801006, 22.4058581648, 12.3758921160, 17.7505028467
Model Training Ended ... Mon Jan  3 02:08:00 2022
pred_METR-LA_GraphWaveNet_2201030132 testing started Mon Jan  3 02:08:00 2022
TEST XS.shape, YS.shape (3507, 2, 69, 12) (3507, 3, 69, 1)
Model Testing Started ... Mon Jan  3 02:08:00 2022
TIMESTEP_IN, TIMESTEP_OUT 12 3
YS.shape, YS_pred.shape before, (3507, 3, 69, 1) (3507, 3, 69, 1)
YS.shape, YS_pred.shape after, (3507, 3, 69) (3507, 3, 69)
YS.shape, YS_pred.shape, (3507, 3, 69) (3507, 3, 69)
****************************************
GraphWaveNet, test, Torch MSE, 4.5224417521e-01, 0.4522441752
all pred steps, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 4314.6122412609, 65.6857080441, 36.6789617686, 56.2101242044
1 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 2515.7341851524, 50.1570950629, 28.6152521501, 42.5490219675
2 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 4491.2500442559, 67.0167892715, 37.6643658470, 56.1368584339
3 step, GraphWaveNet, test, MSE, RMSE, MAE, MAPE, 5936.8414437602, 77.0509016414, 43.7572123238, 69.9444165808
Model Testing Ended ... Mon Jan  3 02:08:02 2022
